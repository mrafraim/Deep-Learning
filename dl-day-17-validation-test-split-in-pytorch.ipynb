{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mrafraim/dl-day-17-validation-test-split-in-pytorch?scriptVersionId=288185651\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"794e72bf","metadata":{"papermill":{"duration":0.005434,"end_time":"2025-12-24T09:58:35.05842","exception":false,"start_time":"2025-12-24T09:58:35.052986","status":"completed"},"tags":[]},"source":["# Day 17: Validation & Test Split in PyTorch\n","\n","Welcome to Day 17!\n","\n","Today you'll learn:\n","- Understand the difference between training, validation, and test sets\n","- Learn how to split data properly in PyTorch\n","- Implement metrics to evaluate model performance\n","- Prepare for early stopping and hyperparameter tuning\n","\n","If you found this notebook helpful, your **<b style=\"color:red;\">UPVOTE</b>** would be greatly appreciated! It helps others discover the work and supports continuous improvement.\n","\n","---"]},{"cell_type":"markdown","id":"b0a160f1","metadata":{"papermill":{"duration":0.003838,"end_time":"2025-12-24T09:58:35.066508","exception":false,"start_time":"2025-12-24T09:58:35.06267","status":"completed"},"tags":[]},"source":["# Why Validation & Test Split?\n","\n","- **Training set:** Used to fit the model  \n","- **Validation set:** Used to tune hyperparameters, monitor overfitting  \n","- **Test set:** Used only to evaluate final model performance  \n","  \n","> Never use the validation or test set for training. Doing so leads to overfitting and unrealistic performance estimates."]},{"cell_type":"markdown","id":"75892581","metadata":{"papermill":{"duration":0.003855,"end_time":"2025-12-24T09:58:35.074339","exception":false,"start_time":"2025-12-24T09:58:35.070484","status":"completed"},"tags":[]},"source":["# Sample Dataset (PyTorch Tensors)"]},{"cell_type":"code","execution_count":1,"id":"67c28fb0","metadata":{"execution":{"iopub.execute_input":"2025-12-24T09:58:35.083727Z","iopub.status.busy":"2025-12-24T09:58:35.083355Z","iopub.status.idle":"2025-12-24T09:58:44.145182Z","shell.execute_reply":"2025-12-24T09:58:44.144203Z"},"papermill":{"duration":9.069269,"end_time":"2025-12-24T09:58:44.147321","exception":false,"start_time":"2025-12-24T09:58:35.078052","status":"completed"},"tags":[]},"outputs":[],"source":["import torch\n","from sklearn.model_selection import train_test_split\n","\n","# 100 samples, 2 features\n","X = torch.randn(100, 2)\n","y = X[:, 0] * 2 + X[:, 1] * -3 + torch.randn(100) * 0.5  # Linear relationship + noise\n","y = y.unsqueeze(1)  # Make it (100,1) for regression\n"]},{"cell_type":"markdown","id":"03f7d832","metadata":{"papermill":{"duration":0.003689,"end_time":"2025-12-24T09:58:44.154994","exception":false,"start_time":"2025-12-24T09:58:44.151305","status":"completed"},"tags":[]},"source":["```python\n","X = torch.randn(100, 2)\n","```\n","\n","* Purpose: Create a dataset of features for regression.\n","* **`100`** → number of samples (rows).\n","* **`2`** → number of features (columns).\n","* **`torch.randn`** → generates random numbers from a standard normal distribution (mean = 0, std = 1).\n","* Shape of `X`: `(100, 2)`\n","\n","Example values of `X` (first 4 rows):\n","\n","```\n","[[ 0.5, -1.2],\n"," [ 0.1,  0.7],\n"," [-0.3,  0.4],\n"," [ 1.0, -0.5]]\n","```\n","\n","\n","\n","```python\n","y = X[:, 0] * 2 + X[:, 1] * -3 + torch.randn(100) * 0.5\n","```\n","\n","* Purpose: Define a linear relationship between features and target `y`, with some random noise.\n","* `X[:, 0]` → first column (feature 1)\n","* `X[:, 1]` → second column (feature 2)\n","* Linear formula applied:\n","\n","$$\n","y = 2 \\cdot X_1 - 3 \\cdot X_2\n","$$\n","\n","* `torch.randn(100) * 0.5` → adds noise to simulate real-world data (std = 0.5).\n","* Shape of `y`: `(100,)` → 1D tensor (100 target values).\n","\n","Example values of `y` (first 4 rows):\n","\n","```\n","[ 0.73, -1.12,  2.45, 0.01]\n","```\n","\n","\n","\n","```python\n","y = y.unsqueeze(1)\n","```\n","\n","* Purpose: Convert `y` from 1D to column vector, required by PyTorch regression models.\n","* `unsqueeze(1)` → adds a new dimension at index 1.\n","* Shape of `y` after unsqueeze: `(100, 1)`\n","\n","Example values after unsqueeze:\n","\n","```\n","[[ 0.73],\n"," [-1.12],\n"," [ 2.45],\n"," [ 0.01]]\n","```\n","\n","* Each row now corresponds to one sample’s target value."]},{"cell_type":"markdown","id":"35d6f09e","metadata":{"papermill":{"duration":0.003772,"end_time":"2025-12-24T09:58:44.162464","exception":false,"start_time":"2025-12-24T09:58:44.158692","status":"completed"},"tags":[]},"source":["# Train / Validation / Test Split"]},{"cell_type":"code","execution_count":2,"id":"616b4c65","metadata":{"execution":{"iopub.execute_input":"2025-12-24T09:58:44.171766Z","iopub.status.busy":"2025-12-24T09:58:44.171272Z","iopub.status.idle":"2025-12-24T09:58:44.198874Z","shell.execute_reply":"2025-12-24T09:58:44.19795Z"},"papermill":{"duration":0.034842,"end_time":"2025-12-24T09:58:44.201027","exception":false,"start_time":"2025-12-24T09:58:44.166185","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Training samples: 70\n","Validation samples: 15\n","Test samples: 15\n"]}],"source":["# First, split into training + temp (val+test)\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Split temp into validation and test\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","\n","print(f\"Training samples: {X_train.shape[0]}\")\n","print(f\"Validation samples: {X_val.shape[0]}\")\n","print(f\"Test samples: {X_test.shape[0]}\")\n"]},{"cell_type":"markdown","id":"8381c8d4","metadata":{"papermill":{"duration":0.003845,"end_time":"2025-12-24T09:58:44.208942","exception":false,"start_time":"2025-12-24T09:58:44.205097","status":"completed"},"tags":[]},"source":["# Convert to PyTorch Dataset & DataLoader"]},{"cell_type":"code","execution_count":3,"id":"b84641ba","metadata":{"execution":{"iopub.execute_input":"2025-12-24T09:58:44.218149Z","iopub.status.busy":"2025-12-24T09:58:44.217824Z","iopub.status.idle":"2025-12-24T09:58:44.225145Z","shell.execute_reply":"2025-12-24T09:58:44.224319Z"},"papermill":{"duration":0.014343,"end_time":"2025-12-24T09:58:44.226999","exception":false,"start_time":"2025-12-24T09:58:44.212656","status":"completed"},"tags":[]},"outputs":[],"source":["from torch.utils.data import TensorDataset, DataLoader\n","\n","# Training dataset and loader\n","train_dataset = TensorDataset(X_train, y_train)\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","\n","# Validation dataset and loader\n","val_dataset = TensorDataset(X_val, y_val)\n","val_loader = DataLoader(val_dataset, batch_size=16)\n","\n","# Test dataset and loader\n","test_dataset = TensorDataset(X_test, y_test)\n","test_loader = DataLoader(test_dataset, batch_size=16)\n"]},{"cell_type":"markdown","id":"0d7279b8","metadata":{"execution":{"iopub.execute_input":"2025-12-23T10:34:29.944771Z","iopub.status.busy":"2025-12-23T10:34:29.9445Z","iopub.status.idle":"2025-12-23T10:34:29.951439Z","shell.execute_reply":"2025-12-23T10:34:29.950139Z","shell.execute_reply.started":"2025-12-23T10:34:29.944748Z"},"papermill":{"duration":0.003753,"end_time":"2025-12-24T09:58:44.234669","exception":false,"start_time":"2025-12-24T09:58:44.230916","status":"completed"},"tags":[]},"source":["```python\n","\n","Raw tensors\n","   ↓\n","TensorDataset (pairs X and y)\n","   ↓\n","DataLoader (batching + shuffling)\n","   ↓\n","Training loop\n"]},{"cell_type":"markdown","id":"387186b8","metadata":{"papermill":{"duration":0.00362,"end_time":"2025-12-24T09:58:44.241995","exception":false,"start_time":"2025-12-24T09:58:44.238375","status":"completed"},"tags":[]},"source":["# Simple Linear Model"]},{"cell_type":"code","execution_count":4,"id":"328e4b89","metadata":{"execution":{"iopub.execute_input":"2025-12-24T09:58:44.251296Z","iopub.status.busy":"2025-12-24T09:58:44.250724Z","iopub.status.idle":"2025-12-24T09:58:44.262024Z","shell.execute_reply":"2025-12-24T09:58:44.261106Z"},"papermill":{"duration":0.018609,"end_time":"2025-12-24T09:58:44.264245","exception":false,"start_time":"2025-12-24T09:58:44.245636","status":"completed"},"tags":[]},"outputs":[],"source":["import torch.nn as nn\n","\n","# nn.Sequential() is ordered container of layers\n","# Input flows through each layer in order automatically.\n","model = nn.Sequential(\n","    nn.Linear(2, 1) ) # Linear layer: 2 input features → 1 output\n"]},{"cell_type":"markdown","id":"ab3147a4","metadata":{"papermill":{"duration":0.003888,"end_time":"2025-12-24T09:58:44.273037","exception":false,"start_time":"2025-12-24T09:58:44.269149","status":"completed"},"tags":[]},"source":["# Define Loss & Optimizer"]},{"cell_type":"code","execution_count":5,"id":"6bdc19d2","metadata":{"execution":{"iopub.execute_input":"2025-12-24T09:58:44.282755Z","iopub.status.busy":"2025-12-24T09:58:44.282225Z","iopub.status.idle":"2025-12-24T09:58:50.859527Z","shell.execute_reply":"2025-12-24T09:58:50.858667Z"},"papermill":{"duration":6.584906,"end_time":"2025-12-24T09:58:50.861756","exception":false,"start_time":"2025-12-24T09:58:44.27685","status":"completed"},"tags":[]},"outputs":[],"source":["criterion = nn.MSELoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"]},{"cell_type":"markdown","id":"6f03571a","metadata":{"papermill":{"duration":0.003708,"end_time":"2025-12-24T09:58:50.869462","exception":false,"start_time":"2025-12-24T09:58:50.865754","status":"completed"},"tags":[]},"source":["# Training Loop with Validation Check"]},{"cell_type":"code","execution_count":6,"id":"37be9fec","metadata":{"execution":{"iopub.execute_input":"2025-12-24T09:58:50.879172Z","iopub.status.busy":"2025-12-24T09:58:50.878401Z","iopub.status.idle":"2025-12-24T09:58:51.102203Z","shell.execute_reply":"2025-12-24T09:58:51.101056Z"},"papermill":{"duration":0.2311,"end_time":"2025-12-24T09:58:51.104235","exception":false,"start_time":"2025-12-24T09:58:50.873135","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0: Train Loss = 10.6214, Val Loss = 10.4218\n","Epoch 10: Train Loss = 1.6957, Val Loss = 1.6869\n","Epoch 20: Train Loss = 0.4307, Val Loss = 0.4168\n","Epoch 30: Train Loss = 0.2349, Val Loss = 0.2115\n","Epoch 40: Train Loss = 0.1990, Val Loss = 0.1672\n"]}],"source":["epochs = 50\n","\n","for epoch in range(epochs):\n","    model.train()                             # Tells PyTorch the model is in training mode\n","    train_loss = 0\n","    for xb, yb in train_loader:               # Iterate over batches of data (xb = input batch, yb = target batch)\n","        optimizer.zero_grad()                 # Reset gradients before this batch\n","        preds = model(xb)                     # Pass batch xb through the model\n","        loss = criterion(preds, yb)           # Measures how far predictions are from true values\n","        loss.backward()                       # Computes gradients of loss w.r.t. all model parameters\n","        optimizer.step()                      # Optimizer updates all weights using computed gradients and learning rate\n","        train_loss += loss.item() * xb.size(0)# Multiply by batch size → convert batch average to total sum over samples\n","    \n","    train_loss /= len(train_loader.dataset)   # Divide by total number of training samples → average loss per sample\n","    \n","    # Validation\n","    model.eval()                              # evaluation mode\n","    val_loss = 0\n","    with torch.no_grad():                     # no gradients are computed, faster and saves memory.we do not update weights during validation\n","        for xb, yb in val_loader:\n","            preds = model(xb)\n","            loss = criterion(preds, yb)\n","            val_loss += loss.item() * xb.size(0)\n","    val_loss /= len(val_loader.dataset)       # average loss per sample for the validation set\n","    \n","    if epoch % 10 == 0:\n","        print(f\"Epoch {epoch}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n"]},{"cell_type":"markdown","id":"dd747f76","metadata":{"papermill":{"duration":0.003738,"end_time":"2025-12-24T09:58:51.112082","exception":false,"start_time":"2025-12-24T09:58:51.108344","status":"completed"},"tags":[]},"source":["The model’s training and validation loss both decrease steadily over epochs, with rapid improvement in early epochs. By epoch 40, the training loss reaches ~0.19 and validation loss ~0.20, indicating that the model has learned the underlying pattern in the data and is generalizing well, with no significant overfitting observed."]},{"cell_type":"markdown","id":"f703b5f2","metadata":{"papermill":{"duration":0.003677,"end_time":"2025-12-24T09:58:51.119526","exception":false,"start_time":"2025-12-24T09:58:51.115849","status":"completed"},"tags":[]},"source":["# Evaluate on Test Set"]},{"cell_type":"code","execution_count":7,"id":"5f953ef1","metadata":{"execution":{"iopub.execute_input":"2025-12-24T09:58:51.129297Z","iopub.status.busy":"2025-12-24T09:58:51.128418Z","iopub.status.idle":"2025-12-24T09:58:51.136261Z","shell.execute_reply":"2025-12-24T09:58:51.135285Z"},"papermill":{"duration":0.014571,"end_time":"2025-12-24T09:58:51.137915","exception":false,"start_time":"2025-12-24T09:58:51.123344","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Loss: 0.1757\n"]}],"source":["model.eval()                                   # set model to evaluation mode\n","test_loss = 0  \n","with torch.no_grad():                          # no gradient computation needed\n","    for xb, yb in test_loader:                 # iterate over test batches\n","        preds = model(xb)                      # forward pass\n","        loss = criterion(preds, yb)            # compute batch loss\n","        test_loss += loss.item() * xb.size(0)  # accumulate total loss\n","test_loss /= len(test_loader.dataset)          # average loss per sample\n","print(f\"Test Loss: {test_loss:.4f}\")\n"]},{"cell_type":"markdown","id":"818d2f53","metadata":{"papermill":{"duration":0.003903,"end_time":"2025-12-24T09:58:51.145725","exception":false,"start_time":"2025-12-24T09:58:51.141822","status":"completed"},"tags":[]},"source":["The model achieves a test loss of ~0.205, which is very close to the final training (0.193) and validation (0.198) losses. This indicates that the model has learned the underlying pattern in the data effectively and generalizes well to unseen samples."]},{"cell_type":"markdown","id":"6b782f7a","metadata":{"papermill":{"duration":0.003799,"end_time":"2025-12-24T09:58:51.153433","exception":false,"start_time":"2025-12-24T09:58:51.149634","status":"completed"},"tags":[]},"source":["# Metrics"]},{"cell_type":"markdown","id":"80230e10","metadata":{"papermill":{"duration":0.003796,"end_time":"2025-12-24T09:58:51.161011","exception":false,"start_time":"2025-12-24T09:58:51.157215","status":"completed"},"tags":[]},"source":["## MSE\n","\n","* MSE measures how far your predictions are from the true values\n","* Think: “On average, how wrong am I?”\n","\n","$$\n","\\text{MSE} = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2\n","$$\n","\n","Where:\n","\n","* $y_i$ = true value\n","* $\\hat{y}_i$ = predicted value\n","* $N$ = number of samples\n","* Squaring → penalizes bigger mistakes more heavily\n","\n","Example:\n","\n","* True targets: `[2, 4, 6]`\n","* Model predicts: `[2.5, 3.5, 5.0]`\n","\n","1. Compute errors: `[0.5, -0.5, -1.0]`\n","2. Square errors: `[0.25, 0.25, 1.0]`\n","3. Average: `(0.25+0.25+1)/3 = 0.5`\n","\n","MSE = 0.5 → small error on average\n","\n","* Bigger mistakes → squared → much larger contribution to MSE\n","\n","Note:\n","\n","* MSE = average squared “distance” between prediction and true value\n","* Small MSE → model is close to true values\n","* Large MSE → predictions are far off"]},{"cell_type":"markdown","id":"92e07679","metadata":{"papermill":{"duration":0.005086,"end_time":"2025-12-24T09:58:51.171551","exception":false,"start_time":"2025-12-24T09:58:51.166465","status":"completed"},"tags":[]},"source":["## R² Score\n","* R² tells you how much of the variation in the data your model explains\n","* Think: “How much better is my model than just guessing the mean?”\n","\n","$$\n","R^2 = 1 - \\frac{\\text{Error of my model}}{\\text{Error of mean model}}\n","$$\n","\n","Where:\n","\n","* **Error of my model** = sum of squared differences between predictions and true values\n","* **Error of mean model** = sum of squared differences between true values and mean of true values\n","\n","**Actual formula:**\n","\n","$$\n","R^2 = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\n","$$\n","\n","where\n","* $y_i$ → true value\n","* $\\hat{y}_i$ → model prediction\n","* $\\bar{y}$ → mean of true values\n","\n","Example:\n","\n","* True targets: `[2, 4, 6]`\n","* Model predicts: `[2.1, 3.9, 6.2]`\n","* Mean of targets: `(2+4+6)/3 = 4`\n","* **Error of model** → small, predictions close to true values\n","* **Error of mean** → bigger, just guessing the mean every time\n","\n","$$\n","R^2 = 1 - \\frac{\\text{small error}}{\\text{big error}} \\approx 0.95\n","$$\n","\n","* R² ≈ 1 → model is very good\n","* R² ≈ 0 → model is as good as predicting the mean\n","* R² < 0 → model is worse than predicting the mean\n","\n"]},{"cell_type":"code","execution_count":8,"id":"9c9c6ddb","metadata":{"execution":{"iopub.execute_input":"2025-12-24T09:58:51.18272Z","iopub.status.busy":"2025-12-24T09:58:51.182187Z","iopub.status.idle":"2025-12-24T09:58:51.190763Z","shell.execute_reply":"2025-12-24T09:58:51.189701Z"},"papermill":{"duration":0.015831,"end_time":"2025-12-24T09:58:51.19253","exception":false,"start_time":"2025-12-24T09:58:51.176699","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["MSE: 0.1757, R2 Score: 0.9796\n"]}],"source":["from sklearn.metrics import mean_squared_error, r2_score\n","\n","# Get predictions on test set\n","y_test_pred = model(X_test).detach().numpy() # Get predicted values from the model as a NumPy array (no gradients)\n","y_test_true = y_test.numpy()                 # Convert true targets to NumPy array for metric computation\n","\n","mse = mean_squared_error(y_test_true, y_test_pred)\n","r2 = r2_score(y_test_true, y_test_pred)\n","\n","print(f\"MSE: {mse:.4f}, R2 Score: {r2:.4f}\")\n"]},{"cell_type":"markdown","id":"c24b78da","metadata":{"papermill":{"duration":0.004498,"end_time":"2025-12-24T09:58:51.201504","exception":false,"start_time":"2025-12-24T09:58:51.197006","status":"completed"},"tags":[]},"source":["| Step             | Action                         | Output                          |\n","| ---------------- | ------------------------------ | ------------------------------- |\n","| `model(X_test)`  | Forward pass through the model | Predictions as a PyTorch tensor |\n","| `.detach()`      | Remove gradients               | Same tensor, no tracking        |\n","| `.numpy()`       | Convert to NumPy array         | Array ready for metrics         |\n","| `y_test.numpy()` | Convert true targets           | NumPy array for comparison      |\n"]},{"cell_type":"markdown","id":"a2d18a5e","metadata":{"papermill":{"duration":0.004426,"end_time":"2025-12-24T09:58:51.210432","exception":false,"start_time":"2025-12-24T09:58:51.206006","status":"completed"},"tags":[]},"source":["The model demonstrates strong predictive performance, achieving a low MSE (0.166) and a high R² (0.976), indicating it explains nearly all variance in the target. Given consistent validation and test results, this suggests good generalization rather than overfitting."]},{"cell_type":"markdown","id":"9d7588d7","metadata":{"papermill":{"duration":0.00433,"end_time":"2025-12-24T09:58:51.219329","exception":false,"start_time":"2025-12-24T09:58:51.214999","status":"completed"},"tags":[]},"source":["# Key Takeaways from Day 17\n","\n","- Validation set helps monitor generalization and prevent overfitting  \n","- Test set is strictly for final performance evaluation  \n","- Always split data before training to avoid data leakage  \n","- Use loss curves to visualize training vs validation  \n","- Metrics like MSE, R2, or accuracy quantify performance on unseen data\n","\n","---"]},{"cell_type":"markdown","id":"13c4c80c","metadata":{"papermill":{"duration":0.004454,"end_time":"2025-12-24T09:58:51.22814","exception":false,"start_time":"2025-12-24T09:58:51.223686","status":"completed"},"tags":[]},"source":["<p style=\"text-align:center; font-size:18px;\">\n","© 2025 Mostafizur Rahman\n","</p>\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31234,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"papermill":{"default_parameters":{},"duration":22.649282,"end_time":"2025-12-24T09:58:54.006395","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-12-24T09:58:31.357113","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}