{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mrafraim/dl-day-29-sentiment-prediction?scriptVersionId=291811609\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"fe653e14","metadata":{"papermill":{"duration":0.005884,"end_time":"2026-01-14T10:06:31.382084","exception":false,"start_time":"2026-01-14T10:06:31.3762","status":"completed"},"tags":[]},"source":["# Day 29: RNN Mini Project - Sentiment Prediction\n","\n","Welcome to Day 29!\n","\n","Today you’ll learn:\n","\n","1. How to preprocess text for RNN (tokenization, encoding, padding)\n","2. How to define a simple RNN in PyTorch\n","3. How to train RNN on small dataset\n","4. How to evaluate predictions\n","5. How hidden states capture sequence patterns\n","6. End-to-end workflow from raw text → prediction\n","\n","By the end of this notebook, you will have built your first end-to-end text classifier.\n","\n","If you found this notebook helpful, your **<b style=\"color:orange;\">UPVOTE</b>** would be greatly appreciated! It helps others discover the work and supports continuous improvement.\n","\n","---\n"]},{"cell_type":"markdown","id":"9525753d","metadata":{"papermill":{"duration":0.004388,"end_time":"2026-01-14T10:06:31.391204","exception":false,"start_time":"2026-01-14T10:06:31.386816","status":"completed"},"tags":[]},"source":["# Import Libraries"]},{"cell_type":"code","execution_count":1,"id":"69310e2d","metadata":{"execution":{"iopub.execute_input":"2026-01-14T10:06:31.401919Z","iopub.status.busy":"2026-01-14T10:06:31.401504Z","iopub.status.idle":"2026-01-14T10:06:39.115514Z","shell.execute_reply":"2026-01-14T10:06:39.11462Z"},"papermill":{"duration":7.722043,"end_time":"2026-01-14T10:06:39.117719","exception":false,"start_time":"2026-01-14T10:06:31.395676","status":"completed"},"tags":[]},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.nn.utils.rnn import pad_sequence\n","import numpy as np"]},{"cell_type":"markdown","id":"c87841bd","metadata":{"papermill":{"duration":0.004084,"end_time":"2026-01-14T10:06:39.126257","exception":false,"start_time":"2026-01-14T10:06:39.122173","status":"completed"},"tags":[]},"source":["# Tiny Sentiment Dataset"]},{"cell_type":"code","execution_count":2,"id":"e91d79a0","metadata":{"execution":{"iopub.execute_input":"2026-01-14T10:06:39.136934Z","iopub.status.busy":"2026-01-14T10:06:39.136386Z","iopub.status.idle":"2026-01-14T10:06:39.173325Z","shell.execute_reply":"2026-01-14T10:06:39.172264Z"},"papermill":{"duration":0.044924,"end_time":"2026-01-14T10:06:39.175548","exception":false,"start_time":"2026-01-14T10:06:39.130624","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["('I love this movie',\n"," 'This film is great',\n"," 'I hate this movie',\n"," 'This film is awful')"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["data = [\n","    (\"I love this movie\", 1),   # positive\n","    (\"This film is great\", 1),  # positive\n","    (\"I hate this movie\", 0),   # negative\n","    (\"This film is awful\", 0)   # negative\n","]\n","\n","sentences, labels = zip(*data)  # zip(*data) unzips the list of tuples\n","labels = torch.tensor(labels)\n","sentences\n"]},{"cell_type":"markdown","id":"b83aeb08","metadata":{"papermill":{"duration":0.00443,"end_time":"2026-01-14T10:06:39.184814","exception":false,"start_time":"2026-01-14T10:06:39.180384","status":"completed"},"tags":[]},"source":["# Tokenization "]},{"cell_type":"code","execution_count":3,"id":"200be250","metadata":{"execution":{"iopub.execute_input":"2026-01-14T10:06:39.195939Z","iopub.status.busy":"2026-01-14T10:06:39.195018Z","iopub.status.idle":"2026-01-14T10:06:39.202484Z","shell.execute_reply":"2026-01-14T10:06:39.201377Z"},"papermill":{"duration":0.014978,"end_time":"2026-01-14T10:06:39.204179","exception":false,"start_time":"2026-01-14T10:06:39.189201","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Tokennized Sentences: \n"]},{"data":{"text/plain":["[['i', 'love', 'this', 'movie'],\n"," ['this', 'film', 'is', 'great'],\n"," ['i', 'hate', 'this', 'movie'],\n"," ['this', 'film', 'is', 'awful']]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Word-level tokenization\n","tokenized_sentences = [s.lower().split() for s in sentences]\n","\n","print(\"Tokennized Sentences: \")\n","tokenized_sentences"]},{"cell_type":"markdown","id":"a129f1d2","metadata":{"papermill":{"duration":0.004394,"end_time":"2026-01-14T10:06:39.213282","exception":false,"start_time":"2026-01-14T10:06:39.208888","status":"completed"},"tags":[]},"source":["# Vocabulary Creation"]},{"cell_type":"code","execution_count":4,"id":"9edba4ca","metadata":{"execution":{"iopub.execute_input":"2026-01-14T10:06:39.225062Z","iopub.status.busy":"2026-01-14T10:06:39.224727Z","iopub.status.idle":"2026-01-14T10:06:39.230352Z","shell.execute_reply":"2026-01-14T10:06:39.229307Z"},"papermill":{"duration":0.013487,"end_time":"2026-01-14T10:06:39.232362","exception":false,"start_time":"2026-01-14T10:06:39.218875","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["{'is', 'film', 'movie', 'hate', 'love', 'awful', 'this', 'great', 'i'}\n","Vocabulary size:  9\n"]}],"source":["# Build vocabulary\n","vocab = set()\n","\n","for sentence in tokenized_sentences:\n","    for word in sentence:\n","        vocab.add(word)\n","\n","print(vocab)\n","\n","vocab_size = len(vocab)\n","print(\"Vocabulary size: \", vocab_size)"]},{"cell_type":"code","execution_count":5,"id":"8c7ebd5a","metadata":{"execution":{"iopub.execute_input":"2026-01-14T10:06:39.243846Z","iopub.status.busy":"2026-01-14T10:06:39.243509Z","iopub.status.idle":"2026-01-14T10:06:39.250932Z","shell.execute_reply":"2026-01-14T10:06:39.249953Z"},"papermill":{"duration":0.015636,"end_time":"2026-01-14T10:06:39.252842","exception":false,"start_time":"2026-01-14T10:06:39.237206","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Word to index mapping:\n"]},{"data":{"text/plain":["{'is': 1,\n"," 'film': 2,\n"," 'movie': 3,\n"," 'hate': 4,\n"," 'love': 5,\n"," 'awful': 6,\n"," 'this': 7,\n"," 'great': 8,\n"," 'i': 9}"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Map words to unique integer IDs\n","\n","word_to_idx = {word: idx+1 for idx, word in enumerate(vocab)} # start from 1, 0 reserved for padding\n","idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n","\n","print(\"Word to index mapping:\")\n","word_to_idx"]},{"cell_type":"markdown","id":"e0a4a35e","metadata":{"papermill":{"duration":0.004441,"end_time":"2026-01-14T10:06:39.262052","exception":false,"start_time":"2026-01-14T10:06:39.257611","status":"completed"},"tags":[]},"source":["# Encoding"]},{"cell_type":"code","execution_count":6,"id":"41f65338","metadata":{"execution":{"iopub.execute_input":"2026-01-14T10:06:39.273214Z","iopub.status.busy":"2026-01-14T10:06:39.272234Z","iopub.status.idle":"2026-01-14T10:06:39.327118Z","shell.execute_reply":"2026-01-14T10:06:39.326072Z"},"papermill":{"duration":0.062919,"end_time":"2026-01-14T10:06:39.329482","exception":false,"start_time":"2026-01-14T10:06:39.266563","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Encoded sentences:\n"]},{"data":{"text/plain":["[tensor([9, 5, 7, 3]),\n"," tensor([7, 2, 1, 8]),\n"," tensor([9, 4, 7, 3]),\n"," tensor([7, 2, 1, 6])]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Convert each token in the sentences to its corresponding integer index\n","encoded_sentences = [\n","    torch.tensor([word_to_idx[word] for word in sentence])\n","    for sentence in tokenized_sentences\n","]\n","\n","print(\"Encoded sentences:\")\n","encoded_sentences"]},{"cell_type":"markdown","id":"6d3ca0db","metadata":{"papermill":{"duration":0.00501,"end_time":"2026-01-14T10:06:39.33978","exception":false,"start_time":"2026-01-14T10:06:39.33477","status":"completed"},"tags":[]},"source":["# Pad Sequences"]},{"cell_type":"code","execution_count":7,"id":"46b04441","metadata":{"execution":{"iopub.execute_input":"2026-01-14T10:06:39.351918Z","iopub.status.busy":"2026-01-14T10:06:39.351154Z","iopub.status.idle":"2026-01-14T10:06:39.406372Z","shell.execute_reply":"2026-01-14T10:06:39.405442Z"},"papermill":{"duration":0.063658,"end_time":"2026-01-14T10:06:39.408504","exception":false,"start_time":"2026-01-14T10:06:39.344846","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[9, 5, 7, 3],\n","        [7, 2, 1, 8],\n","        [9, 4, 7, 3],\n","        [7, 2, 1, 6]])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Pad sequences\n","padded_sequences = pad_sequence(encoded_sentences, \n","                                batch_first=True, \n","                                padding_value=0)\n","\n","padded_sequences"]},{"cell_type":"markdown","id":"3b102749","metadata":{"papermill":{"duration":0.004979,"end_time":"2026-01-14T10:06:39.418832","exception":false,"start_time":"2026-01-14T10:06:39.413853","status":"completed"},"tags":[]},"source":["Explanation:\n","\n","- All sequences now have the same length\n","- Ready for batch processing"]},{"cell_type":"markdown","id":"de71e6c6","metadata":{"papermill":{"duration":0.004782,"end_time":"2026-01-14T10:06:39.428365","exception":false,"start_time":"2026-01-14T10:06:39.423583","status":"completed"},"tags":[]},"source":["# Define Simple RNN Model"]},{"cell_type":"code","execution_count":8,"id":"5fff37e5","metadata":{"execution":{"iopub.execute_input":"2026-01-14T10:06:39.439545Z","iopub.status.busy":"2026-01-14T10:06:39.439232Z","iopub.status.idle":"2026-01-14T10:06:39.446371Z","shell.execute_reply":"2026-01-14T10:06:39.445453Z"},"papermill":{"duration":0.015018,"end_time":"2026-01-14T10:06:39.448246","exception":false,"start_time":"2026-01-14T10:06:39.433228","status":"completed"},"tags":[]},"outputs":[],"source":["class SentimentRNN(nn.Module):\n","    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n","        super().__init__()\n","        self.embedding = nn.Embedding(num_embeddings=vocab_size+1,\n","                                      embedding_dim=embed_dim,\n","                                      padding_idx=0)\n","        self.rnn = nn.RNN(input_size=embed_dim,\n","                          hidden_size=hidden_dim,\n","                          batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, \n","                            output_dim)\n","        self.sigmoid = nn.Sigmoid()\n","        \n","    def forward(self, x):\n","        embedded = self.embedding(x)\n","        out, h_n = self.rnn(embedded)\n","        out = self.fc(out[:, -1, :])  # use last hidden state\n","        return self.sigmoid(out)\n"]},{"cell_type":"markdown","id":"cfb25524","metadata":{"papermill":{"duration":0.004696,"end_time":"2026-01-14T10:06:39.457719","exception":false,"start_time":"2026-01-14T10:06:39.453023","status":"completed"},"tags":[]},"source":[" `__init__(...)`\n","\n","* `vocab_size`: number of unique tokens in your vocabulary\n","* `embed_dim`: size of each word vector\n","* `hidden_dim`: RNN memory capacity\n","* `output_dim`: number of output neurons\n","\n","\n","```python\n","self.embedding = nn.Embedding(\n","    num_embeddings=vocab_size + 1,\n","    embedding_dim=embed_dim,\n","    padding_idx=0\n",")\n","```\n","\n","* Converts word indices → dense vectors\n","* Shape:\n","\n","  ```\n","  (batch, seq_len) → (batch, seq_len, embed_dim)\n","  ```\n","\n","**Why `+1`**\n","\n","* Index `0` is reserved for padding\n","* Real tokens start at `1`\n","\n","**Why `padding_idx=0`**\n","\n","* Padding tokens produce zero vectors\n","* Gradients are NOT updated for padding\n","\n","This is non-negotiable for sequence models.\n","\n","\n","```python\n","self.rnn = nn.RNN(\n","    input_size=embed_dim,\n","    hidden_size=hidden_dim,\n","    batch_first=True\n",")\n","```\n","\n","* Processes sequences step by step\n","* Maintains hidden state across time\n","\n","**Input shape**\n","\n","```\n","(batch, seq_len, embed_dim)\n","```\n","\n","**Output**\n","\n","```python\n","out   → (batch, seq_len, hidden_dim)\n","h_n   → (1, batch, hidden_dim)\n","```\n","\n","\n","```python\n","self.fc = nn.Linear(hidden_dim, output_dim)\n","```\n","\n","This maps:\n","\n","```\n","Final hidden state → class score\n","```\n","\n","You are compressing temporal information into a single scalar.\n","\n","\n","```python\n","self.sigmoid = nn.Sigmoid()\n","```\n","\n","This forces output into:\n","\n","```\n","(0, 1)\n","```\n","\n","Meaning:\n","\n","* Probability of positive sentiment\n","\n","\n","`forward(self, x)`\n","\n","This is the actual computation graph.\n","\n","\n","Step 1: Embedding\n","\n","```python\n","embedded = self.embedding(x)\n","```\n","\n","Input:\n","\n","```\n","x → (batch, seq_len)\n","```\n","\n","Output:\n","\n","```\n","embedded → (batch, seq_len, embed_dim)\n","```\n","\n","Raw integers → semantic vectors.\n","\n","\n","Step 2: RNN\n","\n","```python\n","out, h_n = self.rnn(embedded)\n","```\n","\n","* `out`: hidden state at every time step\n","* `h_n`: hidden state at final time step\n","\n","You ignore `h_n` and do this instead:\n","\n","\n","Step 3: Last time step extraction\n","\n","```python\n","out[:, -1, :]\n","```\n","\n","This means:\n","\n","> Use the hidden state of the **last token** as sentence representation.\n","\n","Step 4: Classification\n","\n","```python\n","out = self.fc(out[:, -1, :])\n","```\n","\n","Shape:\n","\n","```\n","(batch, hidden_dim) → (batch, 1)\n","```\n","\n","Step 5: Sigmoid\n","\n","```python\n","return self.sigmoid(out)\n","```\n","\n","Final output:\n","\n","```\n","(batch, 1)\n","```\n","\n","Probability of positive sentiment."]},{"cell_type":"markdown","id":"f4f6bd97","metadata":{"papermill":{"duration":0.004541,"end_time":"2026-01-14T10:06:39.466784","exception":false,"start_time":"2026-01-14T10:06:39.462243","status":"completed"},"tags":[]},"source":["# Initialize Model, Loss, Optimizer"]},{"cell_type":"code","execution_count":9,"id":"87933609","metadata":{"execution":{"iopub.execute_input":"2026-01-14T10:06:39.478401Z","iopub.status.busy":"2026-01-14T10:06:39.477452Z","iopub.status.idle":"2026-01-14T10:06:47.909387Z","shell.execute_reply":"2026-01-14T10:06:47.908415Z"},"papermill":{"duration":8.440336,"end_time":"2026-01-14T10:06:47.911706","exception":false,"start_time":"2026-01-14T10:06:39.47137","status":"completed"},"tags":[]},"outputs":[],"source":["embed_dim = 8\n","hidden_dim = 16\n","output_dim = 1\n","\n","model = SentimentRNN(vocab_size, embed_dim, hidden_dim, output_dim)\n","\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n"]},{"cell_type":"markdown","id":"8bb4cef3","metadata":{"papermill":{"duration":0.005189,"end_time":"2026-01-14T10:06:47.921957","exception":false,"start_time":"2026-01-14T10:06:47.916768","status":"completed"},"tags":[]},"source":["# Training Loop"]},{"cell_type":"code","execution_count":10,"id":"909f13e4","metadata":{"execution":{"iopub.execute_input":"2026-01-14T10:06:47.934728Z","iopub.status.busy":"2026-01-14T10:06:47.933465Z","iopub.status.idle":"2026-01-14T10:06:48.375697Z","shell.execute_reply":"2026-01-14T10:06:48.374348Z"},"papermill":{"duration":0.450696,"end_time":"2026-01-14T10:06:48.377614","exception":false,"start_time":"2026-01-14T10:06:47.926918","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0, Loss: 0.6691\n","Epoch 50, Loss: 0.0033\n","Epoch 100, Loss: 0.0015\n","Epoch 150, Loss: 0.0010\n"]}],"source":["num_epochs = 200                                 # total iterations over the dataset\n","\n","for epoch in range(num_epochs):\n","    optimizer.zero_grad()                        # reset gradients\n","    outputs = model(padded_sequences).squeeze()  # forward pass to get predictions\n","    loss = criterion(outputs, labels.float())    # compute binary cross-entropy loss\n","    loss.backward()                              # compute gradients via backpropagation\n","    optimizer.step()                             # update model parameters\n","    if epoch % 50 == 0:\n","        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")  # print loss every 50 epochs\n","\n"]},{"cell_type":"markdown","id":"d9791b6e","metadata":{"papermill":{"duration":0.005051,"end_time":"2026-01-14T10:06:48.387987","exception":false,"start_time":"2026-01-14T10:06:48.382936","status":"completed"},"tags":[]},"source":["- outputs are probabilities (0 → negative, 1 → positive)\n","- Loss decreases over epochs, meaning the model is learning"]},{"cell_type":"markdown","id":"630f0301","metadata":{"papermill":{"duration":0.004995,"end_time":"2026-01-14T10:06:48.397982","exception":false,"start_time":"2026-01-14T10:06:48.392987","status":"completed"},"tags":[]},"source":["# Predictions"]},{"cell_type":"code","execution_count":11,"id":"d68d158b","metadata":{"execution":{"iopub.execute_input":"2026-01-14T10:06:48.409774Z","iopub.status.busy":"2026-01-14T10:06:48.409373Z","iopub.status.idle":"2026-01-14T10:06:48.426464Z","shell.execute_reply":"2026-01-14T10:06:48.425473Z"},"papermill":{"duration":0.025881,"end_time":"2026-01-14T10:06:48.428776","exception":false,"start_time":"2026-01-14T10:06:48.402895","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(tensor([9.9963e-01, 9.9898e-01, 4.1784e-04, 9.7878e-04]),\n"," tensor([1, 1, 0, 0]))"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["with torch.no_grad():                                # disable gradient calculation for inference/evaluation\n","    predictions = model(padded_sequences).squeeze()  # forward pass to get predicted probabilities\n","    predicted_labels = (predictions >= 0.5).long()   # convert probabilities to 0/1 class labels\n","\n","predictions, predicted_labels                        # display predicted probabilities and class labels\n"]},{"cell_type":"markdown","id":"1e272fca","metadata":{"papermill":{"duration":0.005486,"end_time":"2026-01-14T10:06:48.43983","exception":false,"start_time":"2026-01-14T10:06:48.434344","status":"completed"},"tags":[]},"source":["# Interpret Predictions"]},{"cell_type":"code","execution_count":12,"id":"5f2f773a","metadata":{"execution":{"iopub.execute_input":"2026-01-14T10:06:48.453039Z","iopub.status.busy":"2026-01-14T10:06:48.452693Z","iopub.status.idle":"2026-01-14T10:06:48.45849Z","shell.execute_reply":"2026-01-14T10:06:48.457563Z"},"papermill":{"duration":0.015608,"end_time":"2026-01-14T10:06:48.460703","exception":false,"start_time":"2026-01-14T10:06:48.445095","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["I love this movie → 1\n","This film is great → 1\n","I hate this movie → 0\n","This film is awful → 0\n"]}],"source":["# iterate over sentences and their predicted labels\n","for sentence, pred in zip(sentences, predicted_labels):  \n","    print(f\"{sentence} → {pred.item()}\")  # print each sentence with its predicted label (0 or 1)\n"]},{"cell_type":"markdown","id":"bc0319e7","metadata":{"papermill":{"duration":0.00593,"end_time":"2026-01-14T10:06:48.472639","exception":false,"start_time":"2026-01-14T10:06:48.466709","status":"completed"},"tags":[]},"source":["# End-to-End Flowchart"]},{"cell_type":"markdown","id":"266a1bee","metadata":{"papermill":{"duration":0.005238,"end_time":"2026-01-14T10:06:48.483275","exception":false,"start_time":"2026-01-14T10:06:48.478037","status":"completed"},"tags":[]},"source":["```\n","\n","┌─────────────────────────────┐\n","│ Raw Sentences (Text)        │\n","│ ──────────────────────────  │\n","│ \"i love this movie\"         │\n","│ \"this film is great\"        │\n","│ \"i hate this movie\"         │\n","│ \"this film is awful\"        │\n","└──────────────┬──────────────┘\n","               │\n","               ▼\n","┌─────────────────────────────┐\n","│ Tokenization                │\n","│ ──────────────────────────  │\n","│ [\"i\",\"love\",\"this\",\"movie\"] │\n","│ [\"this\",\"film\",\"is\",\"great\"]│\n","│ [\"i\",\"hate\",\"this\",\"movie\"] │\n","│ [\"this\",\"film\",\"is\",\"awful\"]│\n","└──────────────┬──────────────┘\n","               │\n","               ▼\n","┌─────────────────────────────┐\n","│ Vocabulary Encoding         │\n","│ ──────────────────────────  │\n","│ i → 1, love → 2, this → 3   │\n","│ movie → 4, film → 5         │\n","│ is → 6, great → 7           │\n","│ hate → 8, awful → 9         │\n","└──────────────┬──────────────┘\n","               │\n","               ▼\n","┌─────────────────────────────┐\n","│ Integer Sequences           │\n","│ ──────────────────────────  │\n","│ [1,2,3,4]                   │\n","│ [3,5,6,7]                   │\n","│ [1,8,3,4]                   │\n","│ [3,5,6,9]                   │\n","└──────────────┬──────────────┘\n","               │\n","               ▼\n","┌─────────────────────────────┐\n","│ Padding (pad_sequence)      │\n","│ padding_value = 0           │\n","│ ──────────────────────────  │\n","│ [1,2,3,4]                   │\n","│ [3,5,6,7]                   │\n","│ [1,8,3,4]                   │\n","│ [3,5,6,9]                   │\n","│ Shape: (batch, seq_len)     │\n","└──────────────┬──────────────┘\n","               │\n","               ▼\n","┌─────────────────────────────┐\n","│ Embedding Layer             │\n","│ nn.Embedding                │\n","│ ──────────────────────────  │\n","│ Input: (4, 4)               │\n","│ Output: (4, 4, embed_dim)   │\n","│ embed_dim = 8               │\n","└──────────────┬──────────────┘\n","               │\n","               ▼\n","┌─────────────────────────────┐\n","│ RNN Layer                   │\n","│ nn.RNN                      │\n","│ ──────────────────────────  │\n","│ Input: (4, 4, 8)            │\n","│ Output: (4, 4, 16)          │\n","│ Hidden state h_n: (1,4,16)  │\n","└──────────────┬──────────────┘\n","               │\n","               ▼\n","┌─────────────────────────────┐\n","│ Last Time Step Selection    │\n","│ ──────────────────────────  │\n","│ out[:, -1, :]               │\n","│ Shape: (4, 16)              │\n","└──────────────┬──────────────┘\n","               │\n","               ▼\n","┌─────────────────────────────┐\n","│ Fully Connected Layer       │\n","│ nn.Linear(16 → 1)           │\n","│ ──────────────────────────  │\n","│ Output: (4, 1)              │\n","└──────────────┬──────────────┘\n","               │\n","               ▼\n","┌─────────────────────────────┐\n","│ Sigmoid Activation          │\n","│ ──────────────────────────  │\n","│ Output Probabilities        │\n","│ (0 → negative, 1 → positive)│\n","└──────────────┬──────────────┘\n","               │\n","               ▼\n","┌─────────────────────────────┐\n","│ Thresholding (>= 0.5)       │\n","│ ──────────────────────────  │\n","│ Final Sentiment Labels      │\n","│ 0 = Negative, 1 = Positive  │\n","└─────────────────────────────┘\n","\n","```"]},{"cell_type":"markdown","id":"65f325e6","metadata":{"papermill":{"duration":0.005427,"end_time":"2026-01-14T10:06:48.493972","exception":false,"start_time":"2026-01-14T10:06:48.488545","status":"completed"},"tags":[]},"source":["# Key Takeaways from Day 29\n","\n","- End-to-end RNN workflow:\n","    - Tokenization → Encoding → Padding → Embedding → RNN → Prediction\n","- Hidden state summarizes sequence information\n","- RNNs can capture short-term patterns in text\n","- With LSTM/GRU, longer dependencies become possible\n","- Even a tiny dataset helps conceptually understand sequence modeling\n","\n","---"]},{"cell_type":"markdown","id":"59aea6b7","metadata":{"papermill":{"duration":0.005487,"end_time":"2026-01-14T10:06:48.504769","exception":false,"start_time":"2026-01-14T10:06:48.499282","status":"completed"},"tags":[]},"source":["<p style=\"text-align:center; font-size:18px;\">\n","© 2026 Mostafizur Rahman\n","</p>\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31234,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"papermill":{"default_parameters":{},"duration":25.403284,"end_time":"2026-01-14T10:06:52.03921","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2026-01-14T10:06:26.635926","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}