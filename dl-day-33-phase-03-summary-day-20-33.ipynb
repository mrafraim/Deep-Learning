{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mrafraim/dl-day-33-phase-03-summary-day-20-33?scriptVersionId=295164189\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"ed6fbd71","metadata":{"papermill":{"duration":0.003641,"end_time":"2026-01-31T16:59:47.019833","exception":false,"start_time":"2026-01-31T16:59:47.016192","status":"completed"},"tags":[]},"source":["# Phase 03 Summary: Day 20–33\n","\n","Welcome to Day 33!\n","\n","Topics Covered in Phase 03:\n","\n","✔ CNN fundamentals  \n","✔ CNN training in PyTorch  \n","✔ Filters, gradients, and visualization  \n","✔ RNN, LSTM, GRU intuition  \n","✔ NLP preprocessing  \n","✔ CNN vs RNN decision-making  \n","✔ Regularization techniques  \n","✔ Hyperparameter tuning  \n","\n","If you found this notebook helpful, your **<b style=\"color:orange;\">UPVOTE</b>** would be greatly appreciated! It helps others discover the work and supports continuous improvement.\n","\n","---\n"]},{"cell_type":"markdown","id":"938b0474","metadata":{"papermill":{"duration":0.002489,"end_time":"2026-01-31T16:59:47.025182","exception":false,"start_time":"2026-01-31T16:59:47.022693","status":"completed"},"tags":[]},"source":["# SECTION 1: CNN RECAP (Day 20–23)\n"]},{"cell_type":"markdown","id":"8ad4bdc0","metadata":{"papermill":{"duration":0.002686,"end_time":"2026-01-31T16:59:47.030711","exception":false,"start_time":"2026-01-31T16:59:47.028025","status":"completed"},"tags":[]},"source":["## What CNNs Actually Learn\n","\n","CNNs learn filters (kernels).\n","\n","Each filter:\n","- Is a small weight matrix\n","- Slides over input\n","- Detects a specific pattern\n","\n","Example:\n","- Edge\n","- Curve\n","- Texture\n","- Stroke\n"]},{"cell_type":"markdown","id":"ef79f601","metadata":{"papermill":{"duration":0.002922,"end_time":"2026-01-31T16:59:47.036135","exception":false,"start_time":"2026-01-31T16:59:47.033213","status":"completed"},"tags":[]},"source":["## CNN Filter Shape (Revisited)\n","\n","```python\n","model.conv1.weight.shape\n","\n","```\n","\n","output\n","```python\n","[16, 1, 3, 3]\n","```\n","\n","Meaning:\n","\n","- 16 filters\n","- 1 input channel (grayscale)\n","- 3×3 spatial size\n","- Each filter = one pattern detector."]},{"cell_type":"markdown","id":"48a30ff2","metadata":{"papermill":{"duration":0.002464,"end_time":"2026-01-31T16:59:47.041121","exception":false,"start_time":"2026-01-31T16:59:47.038657","status":"completed"},"tags":[]},"source":["## CNN Training Loop\n","\n","For each batch:\n","1. Forward pass → predictions\n","2. Compute loss\n","3. Backprop → gradients for filters\n","4. Optimizer updates filters\n","\n","This happens thousands of times, not once.\n"]},{"cell_type":"markdown","id":"e3b7430b","metadata":{"papermill":{"duration":0.002464,"end_time":"2026-01-31T16:59:47.046057","exception":false,"start_time":"2026-01-31T16:59:47.043593","status":"completed"},"tags":[]},"source":["# SECTION 2: RNN / LSTM RECAP (Day 24–29)\n"]},{"cell_type":"markdown","id":"867e6051","metadata":{"papermill":{"duration":0.002529,"end_time":"2026-01-31T16:59:47.051158","exception":false,"start_time":"2026-01-31T16:59:47.048629","status":"completed"},"tags":[]},"source":["## Why RNNs Exist\n","\n","CNNs ignore order beyond local windows.\n","\n","RNNs solve:\n","> “What happened *before* matters.”\n","\n","They introduce:\n","- Hidden state\n","- Temporal dependency\n","- Sequential processing\n"]},{"cell_type":"markdown","id":"ac650f40","metadata":{"papermill":{"duration":0.002495,"end_time":"2026-01-31T16:59:47.056158","exception":false,"start_time":"2026-01-31T16:59:47.053663","status":"completed"},"tags":[]},"source":["## RNN Unrolling Intuition\n","\n","At time step $t$:\n","$$\n","h_t = f(x_t, h_{t-1})\n","$$\n","\n","Meaning:\n","- Current output depends on past\n","- Memory flows forward\n"]},{"cell_type":"markdown","id":"9e67230b","metadata":{"papermill":{"duration":0.002456,"end_time":"2026-01-31T16:59:47.061318","exception":false,"start_time":"2026-01-31T16:59:47.058862","status":"completed"},"tags":[]},"source":["## Why LSTM > RNN\n","\n","Plain RNN:\n","- Suffers from vanishing gradients\n","\n","LSTM adds:\n","- Forget gate\n","- Input gate\n","- Output gate\n","\n","Result:\n","- Stable long-term memory\n","- Better gradient flow\n"]},{"cell_type":"markdown","id":"9226c292","metadata":{"papermill":{"duration":0.002501,"end_time":"2026-01-31T16:59:47.066382","exception":false,"start_time":"2026-01-31T16:59:47.063881","status":"completed"},"tags":[]},"source":["## Mini Example: Sequence Prediction\n","\n","Task:\n","> Predict next word given previous words\n","\n","RNN/LSTM:\n","- Processes tokens one-by-one\n","- Updates hidden state\n","- Outputs probabilities at each step\n"]},{"cell_type":"markdown","id":"fe379765","metadata":{"papermill":{"duration":0.002634,"end_time":"2026-01-31T16:59:47.071716","exception":false,"start_time":"2026-01-31T16:59:47.069082","status":"completed"},"tags":[]},"source":["# SECTION 3: CNN vs RNN (Day 30)\n"]},{"cell_type":"markdown","id":"bb01e279","metadata":{"papermill":{"duration":0.002408,"end_time":"2026-01-31T16:59:47.076669","exception":false,"start_time":"2026-01-31T16:59:47.074261","status":"completed"},"tags":[]},"source":["## Architectural Decision Summary\n","\n","| Question | Use CNN | Use RNN |\n","|--------|--------|--------|\n","| Is order critical? | ❌ | ✅ |\n","| Is speed important? | ✅ | ❌ |\n","| Long context needed? | ❌ | ✅ |\n","| Production scale? | ✅ | ❌ |\n","\n","Key insight:\n","> CNN = pattern extractor  \n","> RNN = memory-based model\n"]},{"cell_type":"markdown","id":"9829bf92","metadata":{"papermill":{"duration":0.002398,"end_time":"2026-01-31T16:59:47.081702","exception":false,"start_time":"2026-01-31T16:59:47.079304","status":"completed"},"tags":[]},"source":["# SECTION 4: Regularization (Day 31)\n"]},{"cell_type":"markdown","id":"35bbd4b4","metadata":{"papermill":{"duration":0.002514,"end_time":"2026-01-31T16:59:47.086781","exception":false,"start_time":"2026-01-31T16:59:47.084267","status":"completed"},"tags":[]},"source":["## Dropout Recap\n","\n","Dropout randomly disables neurons:\n","$$\n","\\tilde{h} = h \\cdot r\n","$$\n","\n","Where:\n","- $r \\sim \\text{Bernoulli}(p)$\n","\n","Effect:\n","- Prevents co-adaptation\n","- Improves generalization\n"]},{"cell_type":"markdown","id":"b6ab722a","metadata":{"papermill":{"duration":0.002515,"end_time":"2026-01-31T16:59:47.091803","exception":false,"start_time":"2026-01-31T16:59:47.089288","status":"completed"},"tags":[]},"source":["## BatchNorm vs LayerNorm\n","\n","| Model | Preferred Normalization |\n","|----|------------------------|\n","| CNN | BatchNorm |\n","| RNN | LayerNorm |\n","\n","Reason:\n","- CNN → stable batch statistics\n","- RNN → sequence-length issues\n"]},{"cell_type":"markdown","id":"c7f31445","metadata":{"papermill":{"duration":0.002434,"end_time":"2026-01-31T16:59:47.096757","exception":false,"start_time":"2026-01-31T16:59:47.094323","status":"completed"},"tags":[]},"source":["# SECTION 5: Hyperparameters (Day 32)\n"]},{"cell_type":"markdown","id":"80916f2e","metadata":{"papermill":{"duration":0.002941,"end_time":"2026-01-31T16:59:47.102292","exception":false,"start_time":"2026-01-31T16:59:47.099351","status":"completed"},"tags":[]},"source":["## Learning Rate (Most Critical)\n","\n","Update rule:\n","$$\n","\\theta_{t+1} = \\theta_t - \\alpha \\nabla L\n","$$\n","\n","Rules of thumb:\n","- Too large → divergence\n","- Too small → slow training\n","- Tune LR before architecture\n"]},{"cell_type":"markdown","id":"4089b50c","metadata":{"papermill":{"duration":0.00267,"end_time":"2026-01-31T16:59:47.108399","exception":false,"start_time":"2026-01-31T16:59:47.105729","status":"completed"},"tags":[]},"source":["## CNN vs RNN Hyperparameters\n","\n","| Parameter | CNN | RNN |\n","|--------|-----|-----|\n","| Learning rate | Higher | Lower |\n","| Batch size | Larger | Smaller |\n","| Gradient clipping | Rare | Mandatory |\n","| Optimizer | SGD / Adam | Adam / RMSprop |\n"]},{"cell_type":"markdown","id":"725dc6dc","metadata":{"papermill":{"duration":0.002517,"end_time":"2026-01-31T16:59:47.113601","exception":false,"start_time":"2026-01-31T16:59:47.111084","status":"completed"},"tags":[]},"source":["# Phase 03 Final Takeaways\n","\n","- CNNs learn spatial patterns\n","- RNNs learn temporal dependencies\n","- Training stability is not automatic\n","- Regularization is not optional\n","- Hyperparameters control learning dynamics\n","- Architecture choice is a business decision\n","\n","---\n"]},{"cell_type":"markdown","id":"7da035b8","metadata":{"papermill":{"duration":0.002595,"end_time":"2026-01-31T16:59:47.118857","exception":false,"start_time":"2026-01-31T16:59:47.116262","status":"completed"},"tags":[]},"source":["<p style=\"text-align:center; font-size:18px;\">\n","© 2026 Mostafizur Rahman\n","</p>\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31259,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"papermill":{"default_parameters":{},"duration":4.040432,"end_time":"2026-01-31T16:59:47.542144","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2026-01-31T16:59:43.501712","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}