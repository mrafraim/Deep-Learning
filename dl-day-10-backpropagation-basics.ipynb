{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c14b4ba",
   "metadata": {
    "papermill": {
     "duration": 0.004892,
     "end_time": "2025-12-17T09:05:15.046061",
     "exception": false,
     "start_time": "2025-12-17T09:05:15.041169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Day 10: Backpropagation Basics\n",
    "\n",
    "Welcome to Day 10!\n",
    "\n",
    "Today you will learn:\n",
    "- What backpropagation actually is (not magic)\n",
    "- Why the chain rule is unavoidable\n",
    "- How gradients flow backward\n",
    "- Manual derivative calculations\n",
    "- A small NumPy example that mirrors real training\n",
    "\n",
    "This is the heart of deep learning.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3920ad",
   "metadata": {
    "papermill": {
     "duration": 0.003723,
     "end_time": "2025-12-17T09:05:15.053747",
     "exception": false,
     "start_time": "2025-12-17T09:05:15.050024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# What Is Backpropagation?\n",
    "\n",
    "Backpropagation is NOT an optimization algorithm.\n",
    "\n",
    "It is:\n",
    "> A systematic application of the chain rule to compute gradients efficiently in a neural network.\n",
    "> \n",
    "> Backpropagation is an algorithm that computes the gradients of the loss function with respect to each parameter of a neural network by applying the chain rule backward through the network.\n",
    "\n",
    "\n",
    "### Why Backpropagation Exists\n",
    "\n",
    "A neural network may have millions of parameters.  \n",
    "To train it, we must know how the loss changes with respect to every weight and bias.\n",
    "\n",
    "Formally, we need:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_i} \\quad \\text{and} \\quad \\frac{\\partial L}{\\partial b_i}\n",
    "$$\n",
    "\n",
    "Computing these derivatives independently would be computationally infeasible.\n",
    "\n",
    "Backpropagation solves this by reusing intermediate derivatives.\n",
    "\n",
    "### Core Idea (Chain Rule)\n",
    "\n",
    "Each layer’s output depends on the previous layer:\n",
    "$$\n",
    "a^{[l]} = f(z^{[l]}), \\quad z^{[l]} = W^{[l]} a^{[l-1]} + b^{[l]}\n",
    "$$\n",
    "\n",
    "Using the chain rule:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W^{[l]}}\n",
    "=\n",
    "\\frac{\\partial L}{\\partial a^{[l]}}\n",
    "\\cdot\n",
    "\\frac{\\partial a^{[l]}}{\\partial z^{[l]}}\n",
    "\\cdot\n",
    "\\frac{\\partial z^{[l]}}{\\partial W^{[l]}}\n",
    "$$\n",
    "\n",
    "This allows gradients to flow from the output layer back to the input layer.\n",
    "\n",
    "### What Backpropagation Actually Does\n",
    "\n",
    "- Starts at the loss function\n",
    "- Moves backward layer by layer\n",
    "- Computes gradients for:\n",
    "  - Weights\n",
    "  - Biases\n",
    "  - Activations\n",
    "- Stores gradients so they can be reused efficiently\n",
    "\n",
    "### What Backpropagation Does Not Do\n",
    "\n",
    "- It does not update weights  \n",
    "- It does not choose the learning rate  \n",
    "\n",
    "Those are handled by optimizers (SGD, Adam, RMSProp)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4fc868",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T07:31:40.624700Z",
     "iopub.status.busy": "2025-12-16T07:31:40.624245Z",
     "iopub.status.idle": "2025-12-16T07:31:40.650385Z",
     "shell.execute_reply": "2025-12-16T07:31:40.648763Z",
     "shell.execute_reply.started": "2025-12-16T07:31:40.624662Z"
    },
    "papermill": {
     "duration": 0.003569,
     "end_time": "2025-12-17T09:05:15.060989",
     "exception": false,
     "start_time": "2025-12-17T09:05:15.057420",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Why Chain Rule?\n",
    "\n",
    "In a neural network, the loss does not depend on weights directly.  \n",
    "Each weight influences the loss through a sequence of intermediate variables.\n",
    "\n",
    "Example dependency:\n",
    "$$\n",
    "w \\;\\rightarrow\\; z \\;\\rightarrow\\; a \\;\\rightarrow\\; L\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $w$ = weight  \n",
    "- $z = wx + b$ = linear combination  \n",
    "- $a = f(z)$ = activation output  \n",
    "- $L$ = loss  \n",
    "\n",
    "### Applying the Chain Rule\n",
    "\n",
    "Because of this indirect dependency, we cannot compute $\\frac{dL}{dw}$ in one step.\n",
    "\n",
    "Instead, we break it into pieces:\n",
    "$$\n",
    "\\frac{dL}{dw} =\n",
    "\\frac{dL}{da}\n",
    "\\cdot\n",
    "\\frac{da}{dz}\n",
    "\\cdot\n",
    "\\frac{dz}{dw}\n",
    "$$\n",
    "\n",
    "Each term answers a specific question:\n",
    "- $\\frac{dL}{da}$ → How sensitive is the loss to the neuron’s output?\n",
    "- $\\frac{da}{dz}$ → How does the activation respond to its input?\n",
    "- $\\frac{dz}{dw}$ → How does the weight affect the neuron input?\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "- Neural networks are deep chains of such dependencies.\n",
    "- The chain rule lets us compute gradients layer by layer, starting from the loss.\n",
    "- These gradients tell each weight how much it contributed to the error.\n",
    "\n",
    "Backpropagation is just the repeated application of the chain rule across all layers of the network. Without the chain rule, training deep networks would be computationally impossible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f50b96",
   "metadata": {
    "papermill": {
     "duration": 0.003391,
     "end_time": "2025-12-17T09:05:15.067900",
     "exception": false,
     "start_time": "2025-12-17T09:05:15.064509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Computational Graph (Single Neuron)\n",
    "\n",
    "Given:\n",
    "$$\n",
    "z = wx + b\n",
    "$$\n",
    "$$\n",
    "a = \\sigma(z)\n",
    "$$\n",
    "$$\n",
    "L = (a - y)^2\n",
    "$$\n",
    "\n",
    "We will compute gradients step by step:\n",
    "- $\\frac{dL}{da}$\n",
    "- $\\frac{da}{dz}$\n",
    "- $\\frac{dz}{dw}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab77528",
   "metadata": {
    "papermill": {
     "duration": 0.003464,
     "end_time": "2025-12-17T09:05:15.075067",
     "exception": false,
     "start_time": "2025-12-17T09:05:15.071603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Step 1: Gradient of Loss\n",
    "\n",
    "Loss:\n",
    "$$\n",
    "L = (a - y)^2\n",
    "$$\n",
    "\n",
    "Derivative:\n",
    "$$\n",
    "\\boxed{\\frac{dL}{da} = 2(a - y)}\n",
    "$$\n",
    "\n",
    "This tells:\n",
    "> How much loss changes if activation changes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bbdd9a",
   "metadata": {
    "papermill": {
     "duration": 0.003518,
     "end_time": "2025-12-17T09:05:15.082231",
     "exception": false,
     "start_time": "2025-12-17T09:05:15.078713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Step 2: Sigmoid Derivative\n",
    "\n",
    "Given sigmoid activation:\n",
    "$$\n",
    "a = \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "Rewrite sigmoid in a differentiable form:\n",
    "$$\n",
    "a = (1 + e^{-z})^{-1}\n",
    "$$\n",
    "\n",
    "Differentiate w.r.t. $z$. Using the chain rule:\n",
    "$$\n",
    "\\frac{da}{dz}\n",
    "= -1 \\cdot (1 + e^{-z})^{-2} \\cdot \\frac{d}{dz}(1 + e^{-z})\n",
    "$$\n",
    "\n",
    "Differentiate the inner term:\n",
    "$$\n",
    "\\frac{d}{dz}(1 + e^{-z}) = -e^{-z}\n",
    "$$\n",
    "\n",
    "Substitute back:\n",
    "$$\n",
    "\\frac{da}{dz}\n",
    "= - (1 + e^{-z})^{-2} \\cdot (-e^{-z})\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{e^{-z}}{(1 + e^{-z})^2}\n",
    "$$\n",
    "\n",
    "\n",
    "**Express derivative in terms of $a$**\n",
    "\n",
    "Recall:\n",
    "$$\n",
    "a = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "So:\n",
    "$$\n",
    "1 - a = \\frac{e^{-z}}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "Multiply:\n",
    "$$\n",
    "a(1 - a)\n",
    "= \\frac{1}{1 + e^{-z}} \\cdot \\frac{e^{-z}}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{e^{-z}}{(1 + e^{-z})^2}\n",
    "$$\n",
    "\n",
    "Final result:\n",
    "$$\n",
    "\\boxed{\n",
    "\\frac{da}{dz} = a(1 - a)\n",
    "}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34250572",
   "metadata": {
    "papermill": {
     "duration": 0.004134,
     "end_time": "2025-12-17T09:05:15.089855",
     "exception": false,
     "start_time": "2025-12-17T09:05:15.085721",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Step 3: Linear Part\n",
    "\n",
    "Linear equation:\n",
    "$$\n",
    "z = wx + b\n",
    "$$\n",
    "\n",
    "Derivatives:\n",
    "$$\n",
    "\\boxed{\\frac{dz}{dw} = x}\n",
    "$$\n",
    "$$\n",
    "\\boxed{\\frac{dz}{db} = 1}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fcef3e",
   "metadata": {
    "papermill": {
     "duration": 0.003649,
     "end_time": "2025-12-17T09:05:15.097207",
     "exception": false,
     "start_time": "2025-12-17T09:05:15.093558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Step 4: Putting It All Together\n",
    "\n",
    "Using chain rule:\n",
    "$$\n",
    "\\frac{dL}{dw} =\n",
    "\\frac{dL}{da} \\cdot\n",
    "\\frac{da}{dz} \\cdot\n",
    "\\frac{dz}{dw}\n",
    "$$\n",
    "\n",
    "Substitute:\n",
    "$$\n",
    "\\boxed{\\frac{dL}{dw} =\n",
    "2(a - y) \\cdot a(1 - a) \\cdot x}\n",
    "$$\n",
    "\n",
    "This is backpropagation for one neuron.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beeb8a9",
   "metadata": {
    "papermill": {
     "duration": 0.003482,
     "end_time": "2025-12-17T09:05:15.104294",
     "exception": false,
     "start_time": "2025-12-17T09:05:15.100812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Manual Example (Numbers)\n",
    "\n",
    "Given\n",
    "\n",
    "- Input: $x = 2$\n",
    "- Weight: $w = 0.5$\n",
    "- Bias: $b = 0$\n",
    "- True label: $y = 1$\n",
    "- Activation: Sigmoid\n",
    "- Loss: MSE\n",
    "\n",
    "### 1. Forward Pass\n",
    "\n",
    "Linear step\n",
    "$$\n",
    "z = wx + b = (0.5)(2) + 0 = 1\n",
    "$$\n",
    "\n",
    "Activation\n",
    "$$\n",
    "a = \\sigma(z) = \\frac{1}{1 + e^{-1}} \\approx 0.731\n",
    "$$\n",
    "\n",
    "### 2. Loss Calculation\n",
    "\n",
    "MSE loss\n",
    "$$\n",
    "L = (a - y)^2 = (0.731 - 1)^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "L = (-0.269)^2 \\approx 0.072\n",
    "$$\n",
    "\n",
    "### 3️. Backward Pass (Gradients)\n",
    "\n",
    "We apply the chain rule:\n",
    "\n",
    "$$\n",
    "\\frac{dL}{dw}\n",
    "= \\frac{dL}{da}\n",
    "\\cdot \\frac{da}{dz}\n",
    "\\cdot \\frac{dz}{dw}\n",
    "$$\n",
    "\n",
    "\n",
    "Step 1: Loss gradient w.r.t. activation\n",
    "$$\n",
    "\\frac{dL}{da} = 2(a - y)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dL}{da} = 2(0.731 - 1) = -0.538\n",
    "$$\n",
    "\n",
    "\n",
    "Step 2: Sigmoid derivative\n",
    "$$\n",
    "\\frac{da}{dz} = a(1 - a)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{da}{dz} = 0.731 \\cdot (1 - 0.731)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{da}{dz} \\approx 0.196\n",
    "$$\n",
    "\n",
    "Step 3: Linear derivative\n",
    "$$\n",
    "\\frac{dz}{dw} = x = 2\n",
    "$$\n",
    "\n",
    "Step 4: Final Gradient w.r.t. Weight\n",
    "\n",
    "Multiply all terms:\n",
    "$$\n",
    "\\frac{dL}{dw}\n",
    "= (-0.538) \\cdot (0.196) \\cdot 2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dL}{dw} \\approx -0.211\n",
    "$$\n",
    "\n",
    "\n",
    "Step 5: Gradient w.r.t. Bias (for completeness)\n",
    "\n",
    "Since:\n",
    "$$\n",
    "\\frac{dz}{db} = 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dL}{db}\n",
    "= \\frac{dL}{da} \\cdot \\frac{da}{dz}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dL}{db}\n",
    "= (-0.538)(0.196)\n",
    "\\approx -0.105\n",
    "$$\n",
    "\n",
    "\n",
    "###  Interpretation\n",
    "\n",
    "- Gradient is negative → increase $w$ and $b$\n",
    "- Model prediction ($0.731$) is too low compared to $y = 1$\n",
    "- Gradient descent will push parameters **upward**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d65a41",
   "metadata": {
    "papermill": {
     "duration": 0.003517,
     "end_time": "2025-12-17T09:05:15.111284",
     "exception": false,
     "start_time": "2025-12-17T09:05:15.107767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a35216b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T09:05:15.120351Z",
     "iopub.status.busy": "2025-12-17T09:05:15.119929Z",
     "iopub.status.idle": "2025-12-17T09:05:15.134309Z",
     "shell.execute_reply": "2025-12-17T09:05:15.133143Z"
    },
    "papermill": {
     "duration": 0.021228,
     "end_time": "2025-12-17T09:05:15.136080",
     "exception": false,
     "start_time": "2025-12-17T09:05:15.114852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07232948812851325, -0.21150837113706686, -0.10575418556853343)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Given values\n",
    "x = 2\n",
    "w = 0.5\n",
    "b = 0\n",
    "y = 1\n",
    "\n",
    "# ---------- Forward pass ----------\n",
    "z = w * x + b\n",
    "a = 1 / (1 + np.exp(-z))\n",
    "L = (a - y)**2\n",
    "\n",
    "# ---------- Backward pass ----------\n",
    "# dL/da\n",
    "dL_da = 2 * (a - y)\n",
    "\n",
    "# da/dz (sigmoid derivative)\n",
    "da_dz = a * (1 - a)\n",
    "\n",
    "# dz/dw and dz/db\n",
    "dz_dw = x\n",
    "dz_db = 1\n",
    "\n",
    "# Gradients\n",
    "dL_dw = dL_da * da_dz * dz_dw\n",
    "dL_db = dL_da * da_dz * dz_db\n",
    "\n",
    "L, dL_dw, dL_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62855ff2",
   "metadata": {
    "papermill": {
     "duration": 0.003809,
     "end_time": "2025-12-17T09:05:15.143852",
     "exception": false,
     "start_time": "2025-12-17T09:05:15.140043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Gradient Descent Update\n",
    "\n",
    "Gradient Descent updates parameters by moving them opposite to the gradient, because the gradient points in the direction of maximum increase in loss.\n",
    "\n",
    "### Weight Update\n",
    "\n",
    "Using learning rate $\\eta$:\n",
    "\n",
    "$$\n",
    "w_{\\text{new}} = w - \\eta \\frac{dL}{dw}\n",
    "$$\n",
    "\n",
    "- If $\\frac{dL}{dw} > 0$ → decrease $w$\n",
    "- If $\\frac{dL}{dw} < 0$ → increase $w$\n",
    "\n",
    "This is how the model corrects its mistakes.\n",
    "\n",
    "### Bias Update\n",
    "\n",
    "Bias is updated the same way:\n",
    "\n",
    "$$\n",
    "b_{\\text{new}} = b - \\eta \\frac{dL}{db}\n",
    "$$\n",
    "\n",
    "- Bias shifts the activation left/right\n",
    "- Learning adjusts when the neuron activates\n",
    "\n",
    "### Key Points\n",
    "\n",
    "- Gradients tell which direction to move\n",
    "- Learning rate controls how far to move\n",
    "- Repeating these updates gradually minimizes the loss\n",
    "\n",
    "### One Training Step\n",
    "\n",
    "1. Forward pass → compute prediction\n",
    "2. Compute loss\n",
    "3. Backward pass → compute gradients\n",
    "4. Update $w$ and $b$\n",
    "5. Repeat until convergence\n",
    "\n",
    "This loop is the core engine of neural network learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac05f81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T09:05:15.152894Z",
     "iopub.status.busy": "2025-12-17T09:05:15.152554Z",
     "iopub.status.idle": "2025-12-17T09:05:15.158760Z",
     "shell.execute_reply": "2025-12-17T09:05:15.157778Z"
    },
    "papermill": {
     "duration": 0.012796,
     "end_time": "2025-12-17T09:05:15.160432",
     "exception": false,
     "start_time": "2025-12-17T09:05:15.147636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated w: 0.5211508371137067\n",
      "updated b: 0.010575418556853344\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "w_new = w - lr * dL_dw\n",
    "b_new = b - lr * dL_db\n",
    "\n",
    "print(\"updated w:\", w_new)\n",
    "print(\"updated b:\",b_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb6cac3",
   "metadata": {
    "papermill": {
     "duration": 0.003806,
     "end_time": "2025-12-17T09:05:15.168250",
     "exception": false,
     "start_time": "2025-12-17T09:05:15.164444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Extending to Multiple Layers\n",
    "\n",
    "We extend the single-neuron example to a tiny 2-layer network to see how backprop works step by step.\n",
    "\n",
    "**Network Architecture**\n",
    "\n",
    "- Inputs: $x_1, x_2$\n",
    "- Hidden layer: **2 neurons (ReLU)**\n",
    "- Output layer: **1 neuron (linear)** (the output $\\hat{y}$ is directly equal to the pre-activation $Z_2$.) \n",
    "- Loss: **Mean Squared Error**\n",
    "\n",
    "**Given Values**\n",
    "\n",
    "- input $x_1 = 1$\n",
    "- input $x_2 = 2$\n",
    "- target $y = 3$\n",
    "\n",
    "**Parameters (initial)**\n",
    "\n",
    "Hidden layer:\n",
    "$$\n",
    "W_1 =\n",
    "\\begin{bmatrix}\n",
    "0.5 & -0.4 \\\\\n",
    "0.3 & 0.1\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "b_1 = [0, 0]\n",
    "$$\n",
    "\n",
    "Output layer:\n",
    "$$\n",
    "W_2 = [0.6, -0.2],\n",
    "\\quad\n",
    "b_2 = 0.1\n",
    "$$\n",
    "\n",
    "### 1️. Forward Pass\n",
    "\n",
    "Hidden layer pre-activation\n",
    "$$\n",
    "z_{h1} = 0.5(1) + 0.3(2) = 1.1\n",
    "$$\n",
    "$$\n",
    "z_{h2} = -0.4(1) + 0.1(2) = -0.2\n",
    "$$\n",
    "\n",
    "So:\n",
    "$$\n",
    "Z_1 = [1.1, -0.2]\n",
    "$$\n",
    "\n",
    "Hidden layer activation (ReLU)\n",
    "$$\n",
    "A_1 = [\\max(0,1.1), \\max(0,-0.2)] = [1.1, 0]\n",
    "$$\n",
    "\n",
    "Output layer pre-activation\n",
    "$$\n",
    "\\hat{y} = z_2 = 0.6(1.1) + (-0.2)(0) + 0.1 = 0.76\n",
    "$$\n",
    "\n",
    "Loss\n",
    "$$\n",
    "L = (\\hat{y} - y)^2 = (0.76 - 3)^2 = 5.02\n",
    "$$\n",
    "\n",
    "\n",
    "### 2️. Backward Pass (Chain Rule)\n",
    "\n",
    "Output layer gradient\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\hat{y}} = 2(\\hat{y} - y) = 2(-2.24) = -4.48\n",
    "$$\n",
    "\n",
    "Gradients w.r.t output parameters\n",
    "\n",
    "* $Z_2 = A_1 \\cdot W_2 + b_2$  \n",
    "* $\\frac{\\partial Z_2}{\\partial W_2} = A_1$\n",
    "* Here, the output linear means $\\hat{y}$ is directly equal to the pre-activation $Z_2$.\n",
    "* There is no sigmoid, ReLU, tanh, or other function applied.\n",
    "* Because of that, the derivative of the activation is:\n",
    "  $\n",
    "  \\frac{d\\hat{y}}{dZ_2} = 1\n",
    "  $\n",
    "\n",
    "$$\n",
    "\\boxed{\\frac{\\partial L}{\\partial W_2} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{d\\hat{y}}{dZ_2} \\cdot \\frac{\\partial Z_2}{\\partial W_2}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_2}\n",
    "= A_1 \\cdot \\frac{\\partial L}{\\partial \\hat{y}}\n",
    "= [1.1, 0] \\cdot (-4.48)\n",
    "= [-4.93, 0]\n",
    "$$\n",
    "\n",
    "\n",
    "The output neuron is linear:\n",
    "\n",
    "$$\n",
    "\\hat{y} = Z_2 = W_2 \\cdot A_1 + b_2\n",
    "$$\n",
    "\n",
    "By the chain rule:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b_2} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial b_2}\n",
    "$$\n",
    "\n",
    "We already computed:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\hat{y}} = 2 (\\hat{y} - y) = 2(0.76 - 3) = -4.48\n",
    "$$\n",
    "\n",
    "Since $\\hat{y} = Z_2 = W_2 \\cdot A_1 + b_2$, the derivative w.r.t $b_2$ is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\hat{y}}{\\partial b_2} = 1\n",
    "$$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b_2} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot 1 = -4.48\n",
    "$$\n",
    "\n",
    "\n",
    "### 3️. Backprop into Hidden Layer\n",
    "\n",
    "We can write the entire gradient for hidden layer weights as a single formula:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\frac{\\partial L}{\\partial W_1} = \n",
    "\\frac{\\partial L}{\\partial \\hat{y}} \\;\\cdot\\; \n",
    "\\frac{\\partial \\hat{y}}{\\partial A_1} \\;\\cdot\\; \n",
    "\\frac{\\partial A_1}{\\partial Z_1} \\;\\cdot\\; \n",
    "\\frac{\\partial Z_1}{\\partial W_1}\n",
    "}\n",
    "$$\n",
    "\n",
    "Where each term is:\n",
    "\n",
    "- $ \\frac{\\partial L}{\\partial \\hat{y}} = 2(\\hat{y} - y) $ → derivative of the loss  \n",
    "- $ \\frac{\\partial \\hat{y}}{\\partial A_1} = W_2 $ → output layer weights  \n",
    "- $ \\frac{\\partial A_1}{\\partial Z_1} = \\text{ReLU}'(Z_1)$ → hidden layer activation derivative  \n",
    "- $ \\frac{\\partial Z_1}{\\partial W_1} = X$ → inputs to the hidden layer neuron\n",
    "\n",
    "Gradient flowing into hidden activations\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial A_1}\n",
    "= W_2 \\cdot \\frac{\\partial L}{\\partial \\hat{y}}\n",
    "= [0.6, -0.2] \\cdot (-4.48)\n",
    "= [-2.69, 0.90]\n",
    "$$\n",
    "\n",
    "Apply ReLU derivative\n",
    "ReLU′$(z)$ = 1 if $z>0$, else 0  \n",
    "\n",
    "Since:\n",
    "$$\n",
    "Z_1 = [1.1, -0.2]\n",
    "$$\n",
    "\n",
    "ReLU mask:\n",
    "$$\n",
    "[1, 0]\n",
    "$$\n",
    "\n",
    "So:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial Z_1}\n",
    "= [-2.69, 0.90] \\odot [1, 0]\n",
    "= [-2.69, 0]\n",
    "$$\n",
    "\n",
    "\n",
    "**Gradients w.r.t Hidden Weights**\n",
    "\n",
    "Hidden neuron 1:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_{11}} = x_1 \\cdot (-2.69) = -2.69\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_{21}} = x_2 \\cdot (-2.69) = -5.38\n",
    "$$\n",
    "\n",
    "Hidden neuron 2:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_{12}} = 0\n",
    "\\quad\n",
    "\\frac{\\partial L}{\\partial w_{22}} = 0\n",
    "$$\n",
    "\n",
    "Bias gradients:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b_1} = [-2.69, 0]\n",
    "$$\n",
    "\n",
    "\n",
    "### 4. Gradient Descent Update (η = 0.1)\n",
    "\n",
    "Hidden layer\n",
    "\n",
    "$$\n",
    "W_1^{new} =\n",
    "\\begin{bmatrix}\n",
    "0.5 & -0.4 \\\\\n",
    "0.3 & 0.1\n",
    "\\end{bmatrix}\n",
    "-\n",
    "0.1\n",
    "\\begin{bmatrix}\n",
    "-2.69 & 0 \\\\\n",
    "-5.38 & 0\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0.769 & -0.4 \\\\\n",
    "0.838 & 0.1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_1^{new} = [0.269, 0]\n",
    "$$\n",
    "\n",
    "Output layer\n",
    "$$\n",
    "W_2^{new} = [0.6, -0.2] - 0.1[-4.93, 0] = [1.093, -0.2]\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_2^{new} = 0.1 - 0.1(-4.48) = 0.548\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70c1447",
   "metadata": {
    "papermill": {
     "duration": 0.00367,
     "end_time": "2025-12-17T09:05:15.175831",
     "exception": false,
     "start_time": "2025-12-17T09:05:15.172161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "938c87dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T09:05:15.185192Z",
     "iopub.status.busy": "2025-12-17T09:05:15.184683Z",
     "iopub.status.idle": "2025-12-17T09:05:15.204189Z",
     "shell.execute_reply": "2025-12-17T09:05:15.203043Z"
    },
    "papermill": {
     "duration": 0.026632,
     "end_time": "2025-12-17T09:05:15.206104",
     "exception": false,
     "start_time": "2025-12-17T09:05:15.179472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Pass:\n",
      "Z1: [ 1.1 -0.2]\n",
      "A1: [1.1 0. ]\n",
      "Z2 / y_hat: 0.76\n",
      "Loss: 5.017600000000001\n",
      "\n",
      "Backward Pass:\n",
      "dL/dW2: [-4.928 -0.   ]\n",
      "dL/db2: -4.48\n",
      "dL/dW1:\n",
      " [[-2.688  0.   ]\n",
      " [-5.376  0.   ]]\n",
      "dL/db1: [-2.688  0.   ]\n",
      "\n",
      "Updated Parameters:\n",
      "W1_new:\n",
      " [[ 0.7688 -0.4   ]\n",
      " [ 0.8376  0.1   ]]\n",
      "b1_new: [0.2688 0.    ]\n",
      "W2_new: [ 1.0928 -0.2   ]\n",
      "b2_new: 0.548\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Inputs and target\n",
    "x = np.array([1, 2])\n",
    "y = 3\n",
    "\n",
    "# Parameters (initial)\n",
    "W1 = np.array([[0.5, -0.4],\n",
    "               [0.3,  0.1]])\n",
    "b1 = np.array([0.0, 0.0])\n",
    "\n",
    "W2 = np.array([0.6, -0.2])\n",
    "b2 = 0.1\n",
    "\n",
    "# Learning rate\n",
    "eta = 0.1\n",
    "\n",
    "# ---------- Forward Pass ----------\n",
    "# Hidden layer pre-activation\n",
    "Z1 = W1.T @ x + b1  # shape (2,)\n",
    "# ReLU activation\n",
    "A1 = np.maximum(0, Z1)\n",
    "\n",
    "# Output layer (linear)\n",
    "Z2 = W2 @ A1 + b2\n",
    "y_hat = Z2\n",
    "\n",
    "# Loss (MSE)\n",
    "loss = (y_hat - y)**2\n",
    "print(\"Forward Pass:\")\n",
    "print(\"Z1:\", Z1)\n",
    "print(\"A1:\", A1)\n",
    "print(\"Z2 / y_hat:\", y_hat)\n",
    "print(\"Loss:\", loss)\n",
    "\n",
    "# ---------- Backward Pass ----------\n",
    "# Output layer gradient\n",
    "dL_dyhat = 2 * (y_hat - y)  # dL/dy_hat\n",
    "\n",
    "# Gradients w.r.t output weights and bias\n",
    "dL_dW2 = dL_dyhat * A1\n",
    "dL_db2 = dL_dyhat * 1\n",
    "\n",
    "# Backprop into hidden layer\n",
    "dL_dA1 = W2 * dL_dyhat\n",
    "# ReLU derivative\n",
    "relu_mask = (Z1 > 0).astype(float)\n",
    "dL_dZ1 = dL_dA1 * relu_mask\n",
    "\n",
    "# Gradients w.r.t hidden weights and biases\n",
    "dL_dW1 = np.outer(x, dL_dZ1)  # shape (2,2)\n",
    "dL_db1 = dL_dZ1\n",
    "\n",
    "print(\"\\nBackward Pass:\")\n",
    "print(\"dL/dW2:\", dL_dW2)\n",
    "print(\"dL/db2:\", dL_db2)\n",
    "print(\"dL/dW1:\\n\", dL_dW1)\n",
    "print(\"dL/db1:\", dL_db1)\n",
    "\n",
    "# ---------- Gradient Descent Update ----------\n",
    "W1_new = W1 - eta * dL_dW1\n",
    "b1_new = b1 - eta * dL_db1\n",
    "\n",
    "W2_new = W2 - eta * dL_dW2\n",
    "b2_new = b2 - eta * dL_db2\n",
    "\n",
    "print(\"\\nUpdated Parameters:\")\n",
    "print(\"W1_new:\\n\", W1_new)\n",
    "print(\"b1_new:\", b1_new)\n",
    "print(\"W2_new:\", W2_new)\n",
    "print(\"b2_new:\", b2_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e227b1",
   "metadata": {
    "papermill": {
     "duration": 0.003804,
     "end_time": "2025-12-17T09:05:15.213933",
     "exception": false,
     "start_time": "2025-12-17T09:05:15.210129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Key Takeaways from Day 10\n",
    "\n",
    "- Backpropagation is **chain rule in action**\n",
    "- Gradients flow backward through the network\n",
    "- Learning = gradient descent using backprop gradients\n",
    "- One neuron backprop = same logic as deep networks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18852d03",
   "metadata": {
    "papermill": {
     "duration": 0.003855,
     "end_time": "2025-12-17T09:05:15.221595",
     "exception": false,
     "start_time": "2025-12-17T09:05:15.217740",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style=\"text-align:center; font-size:18px;\">\n",
    "© 2025 Mostafizur Rahman\n",
    "</p>\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.116371,
   "end_time": "2025-12-17T09:05:15.646363",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-17T09:05:09.529992",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
