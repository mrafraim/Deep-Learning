{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mrafraim/dl-day-27-lstm-for-text-sequence-prediction?scriptVersionId=291381585\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"1cb75e4c","metadata":{"papermill":{"duration":0.006433,"end_time":"2026-01-12T05:09:35.701986","exception":false,"start_time":"2026-01-12T05:09:35.695553","status":"completed"},"tags":[]},"source":["# Day 27: LSTM for Text Sequence Prediction\n","\n","\n","Today you’ll learn:\n","1. How text is converted into numbers for neural networks\n","2. What a character-level text model is\n","3. How LSTM processes text one character at a time\n","4. How to build an LSTM model in PyTorch\n","5. How sequence → memory → next-character prediction works\n","6. Why LSTM is better than RNN for text\n","\n","By the end of this notebook, you will understand how language models begin.\n","\n","If you found this notebook helpful, your **<b style=\"color:orange;\">UPVOTE</b>** would be greatly appreciated! It helps others discover the work and supports continuous improvement.\n","\n","---"]},{"cell_type":"markdown","id":"7bbf37d4","metadata":{"papermill":{"duration":0.005205,"end_time":"2026-01-12T05:09:35.712643","exception":false,"start_time":"2026-01-12T05:09:35.707438","status":"completed"},"tags":[]},"source":["# Import Libraries"]},{"cell_type":"code","execution_count":1,"id":"487d6fce","metadata":{"execution":{"iopub.execute_input":"2026-01-12T05:09:35.725396Z","iopub.status.busy":"2026-01-12T05:09:35.724967Z","iopub.status.idle":"2026-01-12T05:09:40.861942Z","shell.execute_reply":"2026-01-12T05:09:40.860534Z"},"papermill":{"duration":5.146364,"end_time":"2026-01-12T05:09:40.864461","exception":false,"start_time":"2026-01-12T05:09:35.718097","status":"completed"},"tags":[]},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import numpy as np"]},{"cell_type":"markdown","id":"36fb71cb","metadata":{"papermill":{"duration":0.00572,"end_time":"2026-01-12T05:09:40.875354","exception":false,"start_time":"2026-01-12T05:09:40.869634","status":"completed"},"tags":[]},"source":["# Problem Setup\n","\n","We are training a next-character prediction model.\n","\n","Rule:\n","> Given characters up to time t, predict the character at time t+1.\n","\n","Example:\n","\n","- Input text: \"hello\"\n","- Training input: \"hell\"\n","- Training target: \"ello\"\n","\n","Meaning:\n","- Given characters so far → predict the next character\n","- This is the foundation of text generation\n"]},{"cell_type":"markdown","id":"299181f1","metadata":{"papermill":{"duration":0.004713,"end_time":"2026-01-12T05:09:40.885264","exception":false,"start_time":"2026-01-12T05:09:40.880551","status":"completed"},"tags":[]},"source":["# Prepare Text Data"]},{"cell_type":"code","execution_count":2,"id":"c026921e","metadata":{"execution":{"iopub.execute_input":"2026-01-12T05:09:40.89827Z","iopub.status.busy":"2026-01-12T05:09:40.896953Z","iopub.status.idle":"2026-01-12T05:09:40.904549Z","shell.execute_reply":"2026-01-12T05:09:40.903373Z"},"papermill":{"duration":0.016339,"end_time":"2026-01-12T05:09:40.906736","exception":false,"start_time":"2026-01-12T05:09:40.890397","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["number of unique characters in our dataset.:  4\n","Index mapping:  {'l': 0, 'h': 1, 'e': 2, 'o': 3}\n"]}],"source":["text = \"hello\"\n","\n","chars = list(set(text))\n","vocab_size = len(chars)\n","\n","# Character ↔ index mappings\n","char_to_idx = {ch: i for i, ch in enumerate(chars)}\n","idx_to_char = {i: ch for ch, i in char_to_idx.items()}\n","\n","print(\"number of unique characters in our dataset.: \",vocab_size)\n","print(\"Index mapping: \", char_to_idx)\n"]},{"cell_type":"markdown","id":"958bda37","metadata":{"papermill":{"duration":0.004718,"end_time":"2026-01-12T05:09:40.916492","exception":false,"start_time":"2026-01-12T05:09:40.911774","status":"completed"},"tags":[]},"source":["Explanation:\n","\n","- Each character becomes a class\n","- This is a classification problem, not regression"]},{"cell_type":"markdown","id":"e84ce6a9","metadata":{"papermill":{"duration":0.004685,"end_time":"2026-01-12T05:09:40.926847","exception":false,"start_time":"2026-01-12T05:09:40.922162","status":"completed"},"tags":[]},"source":["# Encode Input & Target Sequences"]},{"cell_type":"code","execution_count":3,"id":"e71a876d","metadata":{"execution":{"iopub.execute_input":"2026-01-12T05:09:40.938348Z","iopub.status.busy":"2026-01-12T05:09:40.937961Z","iopub.status.idle":"2026-01-12T05:09:40.991845Z","shell.execute_reply":"2026-01-12T05:09:40.990756Z"},"papermill":{"duration":0.062357,"end_time":"2026-01-12T05:09:40.993949","exception":false,"start_time":"2026-01-12T05:09:40.931592","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Input sequence line:  tensor([[1, 2, 0, 0]])\n","Target sequence line:  tensor([[2, 0, 0, 3]])\n"]}],"source":["# Input: h e l l\n","# Target: e l l o\n","input_seq = torch.tensor([[char_to_idx[c] for c in text[:-1]]]) # text[:-1] → all except last\n","target_seq = torch.tensor([[char_to_idx[c] for c in text[1:]]]) # text[1:] → all except first\n","\n","print(\"Input sequence line: \", input_seq)\n","print(\"Target sequence line: \", target_seq)\n"]},{"cell_type":"code","execution_count":4,"id":"cf28c5b1","metadata":{"execution":{"iopub.execute_input":"2026-01-12T05:09:41.006179Z","iopub.status.busy":"2026-01-12T05:09:41.005208Z","iopub.status.idle":"2026-01-12T05:09:41.011213Z","shell.execute_reply":"2026-01-12T05:09:41.010092Z"},"papermill":{"duration":0.014516,"end_time":"2026-01-12T05:09:41.013438","exception":false,"start_time":"2026-01-12T05:09:40.998922","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Input Shape:  torch.Size([1, 4])\n","Target Shape:  torch.Size([1, 4])\n"]}],"source":["print(\"Input Shape: \", input_seq.size())\n","print(\"Target Shape: \", target_seq.size())"]},{"cell_type":"markdown","id":"73146b53","metadata":{"papermill":{"duration":0.004948,"end_time":"2026-01-12T05:09:41.023431","exception":false,"start_time":"2026-01-12T05:09:41.018483","status":"completed"},"tags":[]},"source":["Shape meaning:\n","\n","- Batch size = 1\n","- Sequence length = 4"]},{"cell_type":"markdown","id":"0c73255f","metadata":{"papermill":{"duration":0.004804,"end_time":"2026-01-12T05:09:41.033307","exception":false,"start_time":"2026-01-12T05:09:41.028503","status":"completed"},"tags":[]},"source":["# One-Hot Encoding"]},{"cell_type":"code","execution_count":5,"id":"60ea43d3","metadata":{"execution":{"iopub.execute_input":"2026-01-12T05:09:41.045873Z","iopub.status.busy":"2026-01-12T05:09:41.044589Z","iopub.status.idle":"2026-01-12T05:09:41.109522Z","shell.execute_reply":"2026-01-12T05:09:41.1084Z"},"papermill":{"duration":0.073606,"end_time":"2026-01-12T05:09:41.111768","exception":false,"start_time":"2026-01-12T05:09:41.038162","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(tensor([[[0., 1., 0., 0.],\n","          [0., 0., 1., 0.],\n","          [1., 0., 0., 0.],\n","          [1., 0., 0., 0.]]]),\n"," torch.Size([1, 4, 4]))"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# (batch_size, sequence_length, vocab_size)\n","input_onehot = torch.zeros(1, input_seq.size(1), vocab_size) # (1, 4, 4)\n","\n","for t in range(input_seq.size(1)):\n","    input_onehot[0, t, input_seq[0, t]] = 1\n","\n","input_onehot, input_onehot.size()\n"]},{"cell_type":"markdown","id":"b886739c","metadata":{"papermill":{"duration":0.004996,"end_time":"2026-01-12T05:09:41.121975","exception":false,"start_time":"2026-01-12T05:09:41.116979","status":"completed"},"tags":[]},"source":["- 1 → batch size (number of sequences fed at once)\n","- 4 → sequence length (number of time steps in the sequence)\n","- 4 → vocab_size (dimension of each input vector at a time step)\n","\n","Why one-hot?\n","\n","- Characters are categorical\n","- No numerical ordering exists"]},{"cell_type":"markdown","id":"bda0ce29","metadata":{"papermill":{"duration":0.004844,"end_time":"2026-01-12T05:09:41.131901","exception":false,"start_time":"2026-01-12T05:09:41.127057","status":"completed"},"tags":[]},"source":["# Define LSTM Model"]},{"cell_type":"code","execution_count":6,"id":"1f559891","metadata":{"execution":{"iopub.execute_input":"2026-01-12T05:09:41.144204Z","iopub.status.busy":"2026-01-12T05:09:41.143387Z","iopub.status.idle":"2026-01-12T05:09:41.15056Z","shell.execute_reply":"2026-01-12T05:09:41.149456Z"},"papermill":{"duration":0.01576,"end_time":"2026-01-12T05:09:41.152663","exception":false,"start_time":"2026-01-12T05:09:41.136903","status":"completed"},"tags":[]},"outputs":[],"source":["class CharLSTM(nn.Module):\n","\n","    # vocab_size → number of unique characters (input & output size)\n","    # hidden_size → number of memory units in LSTM (capacity of hidden state)\n","    def __init__(self, vocab_size, hidden_size): \n","        super().__init__()\n","        self.lstm = nn.LSTM(\n","            input_size=vocab_size,   # Each character is represented as a one-hot vector (length = vocab_size).\n","            hidden_size=hidden_size, # Number of hidden units\n","            batch_first=True         # Ensures input shape is (batch, seq_len, input_size)\n","        )\n","        self.fc = nn.Linear(hidden_size, vocab_size)\n","\n","    def forward(self, x):\n","        # out → hidden states at all time steps (shape = [batch, seq_len, hidden_size])\n","        # h_n → hidden state at last time step (short-term memory)\n","        # c_n → cell state at last time step (long-term memory) \n","        out, (h_n, c_n) = self.lstm(x)\n","        out = self.fc(out)\n","        return out\n"]},{"cell_type":"markdown","id":"1c377e96","metadata":{"papermill":{"duration":0.005029,"end_time":"2026-01-12T05:09:41.162864","exception":false,"start_time":"2026-01-12T05:09:41.157835","status":"completed"},"tags":[]},"source":["Key idea:\n","\n","- LSTM returns output at every time step\n","- We predict a character at each step"]},{"cell_type":"markdown","id":"0876c1b6","metadata":{"papermill":{"duration":0.004884,"end_time":"2026-01-12T05:09:41.172866","exception":false,"start_time":"2026-01-12T05:09:41.167982","status":"completed"},"tags":[]},"source":["# Initialize Model, Loss, Optimizer"]},{"cell_type":"code","execution_count":7,"id":"34f0990d","metadata":{"execution":{"iopub.execute_input":"2026-01-12T05:09:41.184952Z","iopub.status.busy":"2026-01-12T05:09:41.184623Z","iopub.status.idle":"2026-01-12T05:09:48.320928Z","shell.execute_reply":"2026-01-12T05:09:48.319467Z"},"papermill":{"duration":7.145299,"end_time":"2026-01-12T05:09:48.32338","exception":false,"start_time":"2026-01-12T05:09:41.178081","status":"completed"},"tags":[]},"outputs":[],"source":["model = CharLSTM(vocab_size=vocab_size, hidden_size=16)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"]},{"cell_type":"markdown","id":"05740ec6","metadata":{"papermill":{"duration":0.004963,"end_time":"2026-01-12T05:09:48.333521","exception":false,"start_time":"2026-01-12T05:09:48.328558","status":"completed"},"tags":[]},"source":["# Forward Pass"]},{"cell_type":"code","execution_count":8,"id":"53ad68ba","metadata":{"execution":{"iopub.execute_input":"2026-01-12T05:09:48.345547Z","iopub.status.busy":"2026-01-12T05:09:48.345062Z","iopub.status.idle":"2026-01-12T05:09:48.4857Z","shell.execute_reply":"2026-01-12T05:09:48.484894Z"},"papermill":{"duration":0.149211,"end_time":"2026-01-12T05:09:48.487873","exception":false,"start_time":"2026-01-12T05:09:48.338662","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["torch.Size([1, 4, 4])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["outputs = model(input_onehot)\n","\n","outputs.shape\n"]},{"cell_type":"markdown","id":"e798ad46","metadata":{"papermill":{"duration":0.005368,"end_time":"2026-01-12T05:09:48.498599","exception":false,"start_time":"2026-01-12T05:09:48.493231","status":"completed"},"tags":[]},"source":["Output shape:\n","\n","`(batch_size, sequence_length, vocab_size)`\n","\n","\n","Each time step predicts a probability distribution over characters."]},{"cell_type":"markdown","id":"5d46347e","metadata":{"papermill":{"duration":0.005163,"end_time":"2026-01-12T05:09:48.509054","exception":false,"start_time":"2026-01-12T05:09:48.503891","status":"completed"},"tags":[]},"source":["# Compute Loss"]},{"cell_type":"code","execution_count":9,"id":"2fb3324b","metadata":{"execution":{"iopub.execute_input":"2026-01-12T05:09:48.522042Z","iopub.status.busy":"2026-01-12T05:09:48.52164Z","iopub.status.idle":"2026-01-12T05:09:48.530218Z","shell.execute_reply":"2026-01-12T05:09:48.529196Z"},"papermill":{"duration":0.017857,"end_time":"2026-01-12T05:09:48.53239","exception":false,"start_time":"2026-01-12T05:09:48.514533","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[[ 0.0957,  0.2240, -0.2886, -0.2502],\n","         [ 0.0990,  0.2228, -0.3222, -0.2476],\n","         [ 0.0598,  0.2162, -0.3424, -0.2362],\n","         [ 0.0427,  0.2180, -0.3554, -0.2359]]], grad_fn=<ViewBackward0>)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["outputs"]},{"cell_type":"code","execution_count":10,"id":"5cf1ecfd","metadata":{"execution":{"iopub.execute_input":"2026-01-12T05:09:48.545438Z","iopub.status.busy":"2026-01-12T05:09:48.545015Z","iopub.status.idle":"2026-01-12T05:09:48.563853Z","shell.execute_reply":"2026-01-12T05:09:48.562823Z"},"papermill":{"duration":0.02864,"end_time":"2026-01-12T05:09:48.566534","exception":false,"start_time":"2026-01-12T05:09:48.537894","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["1.4341862201690674"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["loss = criterion(\n","    outputs.view(-1, vocab_size),\n","    target_seq.view(-1)\n",")\n","\n","loss.item()\n"]},{"cell_type":"markdown","id":"93e541c1","metadata":{"papermill":{"duration":0.00541,"end_time":"2026-01-12T05:09:48.577617","exception":false,"start_time":"2026-01-12T05:09:48.572207","status":"completed"},"tags":[]},"source":["Explanation:\n","\n","- Flatten sequence dimension\n","- Compare predicted vs true characters"]},{"cell_type":"markdown","id":"e06a628b","metadata":{"papermill":{"duration":0.005764,"end_time":"2026-01-12T05:09:48.589587","exception":false,"start_time":"2026-01-12T05:09:48.583823","status":"completed"},"tags":[]},"source":["# Training Loop"]},{"cell_type":"code","execution_count":11,"id":"3af7899b","metadata":{"execution":{"iopub.execute_input":"2026-01-12T05:09:48.602731Z","iopub.status.busy":"2026-01-12T05:09:48.602327Z","iopub.status.idle":"2026-01-12T05:09:49.253321Z","shell.execute_reply":"2026-01-12T05:09:49.252173Z"},"papermill":{"duration":0.660272,"end_time":"2026-01-12T05:09:49.255477","exception":false,"start_time":"2026-01-12T05:09:48.595205","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0, Loss: 1.4342\n","Epoch 50, Loss: 0.1026\n","Epoch 100, Loss: 0.0086\n","Epoch 150, Loss: 0.0041\n","Epoch 200, Loss: 0.0025\n","Epoch 250, Loss: 0.0017\n"]}],"source":["for epoch in range(300):\n","    optimizer.zero_grad()\n","    outputs = model(input_onehot)\n","    \n","    loss = criterion(\n","        outputs.view(-1, vocab_size),\n","        target_seq.view(-1)\n","    )\n","    \n","    loss.backward()\n","    optimizer.step()\n","\n","    if epoch % 50 == 0:\n","        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n"]},{"cell_type":"markdown","id":"cec32cf5","metadata":{"papermill":{"duration":0.005954,"end_time":"2026-01-12T05:09:49.267594","exception":false,"start_time":"2026-01-12T05:09:49.26164","status":"completed"},"tags":[]},"source":["This demonstrates:\n","\n","- Backpropagation Through Time\n","- LSTM learning character transitions"]},{"cell_type":"markdown","id":"3e847598","metadata":{"papermill":{"duration":0.005659,"end_time":"2026-01-12T05:09:49.27919","exception":false,"start_time":"2026-01-12T05:09:49.273531","status":"completed"},"tags":[]},"source":["# Text Prediction"]},{"cell_type":"code","execution_count":12,"id":"db8a54a3","metadata":{"execution":{"iopub.execute_input":"2026-01-12T05:09:49.29375Z","iopub.status.busy":"2026-01-12T05:09:49.293378Z","iopub.status.idle":"2026-01-12T05:09:49.317561Z","shell.execute_reply":"2026-01-12T05:09:49.315711Z"},"papermill":{"duration":0.034976,"end_time":"2026-01-12T05:09:49.320239","exception":false,"start_time":"2026-01-12T05:09:49.285263","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'ello'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["with torch.no_grad():\n","    outputs = model(input_onehot)\n","    predicted_indices = torch.argmax(outputs, dim=2)\n","\n","predicted_text = \"\".join(idx_to_char[i.item()] for i in predicted_indices[0])\n","predicted_text\n"]},{"cell_type":"markdown","id":"6f96734f","metadata":{"papermill":{"duration":0.00642,"end_time":"2026-01-12T05:09:49.332812","exception":false,"start_time":"2026-01-12T05:09:49.326392","status":"completed"},"tags":[]},"source":["Expected behavior:\n","\n","- Output should converge toward \"ello\""]},{"cell_type":"markdown","id":"930d64f1","metadata":{"papermill":{"duration":0.005839,"end_time":"2026-01-12T05:09:49.344653","exception":false,"start_time":"2026-01-12T05:09:49.338814","status":"completed"},"tags":[]},"source":["# Why LSTM Works Here\n","\n","- Text has long-term dependencies\n","- Vanilla RNN forgets early characters\n","- LSTM cell state preserves memory\n","- Gates control information flow\n"]},{"cell_type":"markdown","id":"3ebc9946","metadata":{"papermill":{"duration":0.005897,"end_time":"2026-01-12T05:09:49.356909","exception":false,"start_time":"2026-01-12T05:09:49.351012","status":"completed"},"tags":[]},"source":["# Optional: Memorize ONLY these 5 patterns\n","\n","That’s all experts carry in their head:\n","\n","- Sequence input → (B, T, F)\n","- RNN/LSTM output → (B, T, H)\n","- Hidden state → (num_layers, B, H)\n","- Linear layer → changes last dim only\n","- CrossEntropy → (N, C) vs (N,)\n","- Everything else is derived."]},{"cell_type":"markdown","id":"610dcfb6","metadata":{"papermill":{"duration":0.005756,"end_time":"2026-01-12T05:09:49.368549","exception":false,"start_time":"2026-01-12T05:09:49.362793","status":"completed"},"tags":[]},"source":["# Key Takeaways from Day 2\n","\n","- Text modeling is a sequence prediction problem\n","- Characters are treated as classes\n","- LSTM processes text step by step\n","- Outputs predict the next character\n","- This is the foundation of text generation\n","\n","---"]},{"cell_type":"markdown","id":"7edae7a2","metadata":{"papermill":{"duration":0.005625,"end_time":"2026-01-12T05:09:49.379953","exception":false,"start_time":"2026-01-12T05:09:49.374328","status":"completed"},"tags":[]},"source":["<p style=\"text-align:center; font-size:18px;\">\n","© 2026 Mostafizur Rahman\n","</p>\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31234,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"papermill":{"default_parameters":{},"duration":19.644772,"end_time":"2026-01-12T05:09:51.651498","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2026-01-12T05:09:32.006726","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}