{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mrafraim/dl-day-37-cnn-learning-rate-scheduling?scriptVersionId=298917645\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"0b8fa773","metadata":{"papermill":{"duration":0.006203,"end_time":"2026-02-20T11:31:45.749778","exception":false,"start_time":"2026-02-20T11:31:45.743575","status":"completed"},"tags":[]},"source":["# Day 37: CNN Learning Rate Scheduling\n","StepLR · ReduceLROnPlateau · CosineAnnealing · LR Phase Intuition\n","\n","Welcome to Day 37!\n","\n","What You’ll Learn Today:\n","\n","1. Why fixed learning rates are suboptimal\n","2. Learning rate decay intuition\n","3. StepLR\n","4. ReduceLROnPlateau\n","5. CosineAnnealing\n","6. When to use which\n","\n","If you found this notebook helpful, your **<b style=\"color:skyblue;\">UPVOTE</b>** would be greatly appreciated! It helps others discover the work and supports continuous improvement.\n","\n","---"]},{"cell_type":"markdown","id":"772e3138","metadata":{"papermill":{"duration":0.004763,"end_time":"2026-02-20T11:31:45.759816","exception":false,"start_time":"2026-02-20T11:31:45.755053","status":"completed"},"tags":[]},"source":["# Why Fixed Learning Rate Fails\n","\n","Recall the basic gradient descent update:\n","\n","$$\n","\\boxed{\\theta_{t+1} = \\theta_t - \\alpha \\nabla L(\\theta_t)}\n","$$\n","\n","Where:\n","- $\\theta_t$ → current parameters  \n","- $\\alpha$ → learning rate  \n","- $\\nabla L$ → gradient (direction of steepest increase)\n","\n","We subtract the gradient to move **downhill**."]},{"cell_type":"markdown","id":"8e025260","metadata":{"papermill":{"duration":0.005933,"end_time":"2026-02-20T11:31:45.770435","exception":false,"start_time":"2026-02-20T11:31:45.764502","status":"completed"},"tags":[]},"source":["## What the Learning Rate Really Controls\n","\n","The learning rate $\\alpha$ determines **step size**.\n","\n","It answers:\n","\n","> “How far should we move in the gradient direction?”"]},{"cell_type":"markdown","id":"4fbb1734","metadata":{"papermill":{"duration":0.004625,"end_time":"2026-02-20T11:31:45.779872","exception":false,"start_time":"2026-02-20T11:31:45.775247","status":"completed"},"tags":[]},"source":["## If $\\alpha$ Is Large\n","\n","$$\n","\\theta_{t+1} = \\theta_t - \\textbf{large step}\n","$$\n","\n","### Pros\n","- Fast movement across loss surface  \n","- Escapes sharp local minima  \n","- Explores wider regions  \n","\n","### Cons\n","- Can overshoot minima  \n","- Oscillates around optimum  \n","- May diverge  \n","\n","Large LR is good for:\n","- Early training\n","- Rough exploration"]},{"cell_type":"markdown","id":"ac7f8ce5","metadata":{"papermill":{"duration":0.004641,"end_time":"2026-02-20T11:31:45.789174","exception":false,"start_time":"2026-02-20T11:31:45.784533","status":"completed"},"tags":[]},"source":["## If $\\alpha$ Is Small\n","\n","$$\n","\\theta_{t+1} = \\theta_t - \\textbf{small step}\n","$$\n","\n","### Pros\n","- Stable convergence  \n","- Precise fine-tuning  \n","- Less oscillation  \n","\n","### Cons\n","- Very slow training  \n","- Can get stuck in sharp minima  \n","- Poor exploration  \n","\n","Small LR is good for:\n","- Late training\n","- Fine-grained optimization"]},{"cell_type":"markdown","id":"f110d0a6","metadata":{"papermill":{"duration":0.004731,"end_time":"2026-02-20T11:31:45.79846","exception":false,"start_time":"2026-02-20T11:31:45.793729","status":"completed"},"tags":[]},"source":["## Core Problem\n","\n","Training has two different phases:\n","\n","1️. Exploration phase  \n","2️. Refinement phase  \n","\n","A single fixed $\\alpha$ cannot optimize both:\n","\n","- If large → unstable at end\n","- If small → painfully slow at start "]},{"cell_type":"markdown","id":"bfd8c70a","metadata":{"papermill":{"duration":0.004717,"end_time":"2026-02-20T11:31:45.807821","exception":false,"start_time":"2026-02-20T11:31:45.803104","status":"completed"},"tags":[]},"source":["## Geometric Intuition\n","\n","Think of descending a mountain:\n","\n","- At the top → you want big jumps  \n","- Near the bottom → you want tiny careful steps  \n","\n","Using one fixed step size is inefficient."]},{"cell_type":"markdown","id":"644e75cd","metadata":{"papermill":{"duration":0.004617,"end_time":"2026-02-20T11:31:45.817166","exception":false,"start_time":"2026-02-20T11:31:45.812549","status":"completed"},"tags":[]},"source":["## Strategic Conclusion\n","\n","> Learning rate must change over time.\n","\n","That’s why we use:\n","- Step decay  \n","- Exponential decay  \n","- Cosine annealing  \n","- OneCycle  \n","- Warmup schedules  \n","\n","Fixed LR is simple but strategically weak for deep networks."]},{"cell_type":"markdown","id":"65c1a7aa","metadata":{"papermill":{"duration":0.004776,"end_time":"2026-02-20T11:31:45.826512","exception":false,"start_time":"2026-02-20T11:31:45.821736","status":"completed"},"tags":[]},"source":["# Optimization Has Distinct Phases\n","\n","Training a neural network is **not uniform**.  \n","The geometry of the loss surface and gradient magnitudes change over time."]},{"cell_type":"markdown","id":"cb77ab09","metadata":{"papermill":{"duration":0.004573,"end_time":"2026-02-20T11:31:45.835779","exception":false,"start_time":"2026-02-20T11:31:45.831206","status":"completed"},"tags":[]},"source":["## 1️. Exploration Phase (Early Training)\n","\n","- Loss decreases rapidly  \n","- Gradients are large  \n","- Parameters are far from optimum  \n","\n","Update rule:\n","\n","$$\n","\\theta_{t+1} = \\theta_t - \\alpha \\nabla L(\\theta_t)\n","$$\n","\n","Since $\\|\\nabla L\\|$ is large:\n","\n","- Large $\\alpha$ → fast movement across surface  \n","- Helps escape sharp or poor local regions  \n","- Encourages broader exploration  \n","\n","Goal here:\n","> Move quickly toward a promising basin."]},{"cell_type":"markdown","id":"b7619681","metadata":{"papermill":{"duration":0.004559,"end_time":"2026-02-20T11:31:45.845178","exception":false,"start_time":"2026-02-20T11:31:45.840619","status":"completed"},"tags":[]},"source":["## 2️. Transition Phase (Approaching Minimum)\n","\n","- Parameters enter a valley (basin)  \n","- Gradients shrink but fluctuate  \n","- Curvature becomes important  \n","\n","If $\\alpha$ remains large:\n","\n","- Updates overshoot the minimum  \n","- Oscillations occur across valley walls  \n","\n","Mathematically:\n","\n","Large $\\alpha$ × small but varying $\\nabla L$ → unstable zig-zag behavior  \n","\n","Goal here:\n","> Reduce step size to stabilize descent.\n"]},{"cell_type":"markdown","id":"743e09ad","metadata":{"papermill":{"duration":0.004545,"end_time":"2026-02-20T11:31:45.854313","exception":false,"start_time":"2026-02-20T11:31:45.849768","status":"completed"},"tags":[]},"source":["## 3️. Fine Convergence Phase (Late Training)\n","\n","- Gradients are small  \n","- Surface curvature dominates  \n","- Small adjustments refine solution  \n","\n","Now we need:\n","\n","$$\n","\\alpha \\text{ very small}\n","$$\n","\n","Why?\n","\n","Because near minimum:\n","\n","$$\n","\\nabla L \\approx 0\n","$$\n","\n","Large $\\alpha$ would:\n","- Bounce around minimum  \n","- Prevent precise convergence  \n","\n","Goal here:\n","> Minimize noise and fine-tune parameters."]},{"cell_type":"markdown","id":"0f7890cd","metadata":{"papermill":{"duration":0.004477,"end_time":"2026-02-20T11:31:45.863451","exception":false,"start_time":"2026-02-20T11:31:45.858974","status":"completed"},"tags":[]},"source":["## Fixed Learning Rate Fails\n","\n","A single $\\alpha$ cannot satisfy all phases:\n","\n","| Phase | Ideal LR |\n","|-------|----------|\n","| Exploration | Large |\n","| Transition | Medium |\n","| Fine Convergence | Small |\n","\n","If LR is fixed:\n","\n","- Large LR → never truly settles  \n","- Small LR → wastes early training potential  "]},{"cell_type":"markdown","id":"7dcdfae7","metadata":{"papermill":{"duration":0.004585,"end_time":"2026-02-20T11:31:45.872511","exception":false,"start_time":"2026-02-20T11:31:45.867926","status":"completed"},"tags":[]},"source":["## Core Insight\n","\n","Optimization is **dynamic**.\n","\n","The learning rate should:\n","- Start large  \n","- Gradually decrease  \n","- Become very small near convergence  \n","\n","That’s why we use:\n","\n","- Step decay  \n","- Cosine annealing  \n","- OneCycle policy  \n","- Warmup + decay  \n","\n","> No scheduling = stuck oscillating near the minimum instead of converging smoothly."]},{"cell_type":"markdown","id":"4aa794e4","metadata":{"papermill":{"duration":0.004454,"end_time":"2026-02-20T11:31:45.881619","exception":false,"start_time":"2026-02-20T11:31:45.877165","status":"completed"},"tags":[]},"source":["# What is Learning Rate Scheduling?\n","\n","**Learning rate scheduling** is the strategy of changing the learning rate during training instead of keeping it constant.\n","\n","Instead of using a fixed learning rate:\n","\n","$$\n","\\theta_{t+1} = \\theta_t - \\alpha \\nabla L\n","$$\n","\n","we use a time-dependent learning rate:\n","\n","$$\n","\\boxed{\\theta_{t+1} = \\theta_t - \\alpha_t \\nabla L}\n","$$\n","\n","where $ \\alpha_t $ changes over time.\n"]},{"cell_type":"markdown","id":"f698684f","metadata":{"papermill":{"duration":0.004512,"end_time":"2026-02-20T11:31:45.890732","exception":false,"start_time":"2026-02-20T11:31:45.88622","status":"completed"},"tags":[]},"source":["## Why Do We Need It?\n","\n","Training usually happens in different phases:\n","\n","### 1️. Early Phase > Exploration\n","- Loss decreases rapidly  \n","- Gradients are large  \n","- Larger learning rate helps move quickly  \n","\n","### 2️. Middle Phase > Transition\n","- Approaching a good region  \n","- Oscillations may start  \n","- Learning rate should reduce  \n","\n","### 3️. Final Phase > Fine Convergence\n","- Very small improvements  \n","- Requires precise adjustments  \n","- Small learning rate is necessary  \n","\n","A single fixed learning rate cannot work optimally across all these phases."]},{"cell_type":"markdown","id":"6c8199f0","metadata":{"papermill":{"duration":0.004953,"end_time":"2026-02-20T11:31:45.900363","exception":false,"start_time":"2026-02-20T11:31:45.89541","status":"completed"},"tags":[]},"source":["## What Scheduling Does\n","\n","Learning rate scheduling:\n","\n","- Starts large → enables fast progress  \n","- Gradually reduces → improves stability  \n","- Prevents oscillation near minimum  \n","- Often improves final accuracy  \n"]},{"cell_type":"markdown","id":"9b3a29d0","metadata":{"papermill":{"duration":0.004583,"end_time":"2026-02-20T11:31:45.909875","exception":false,"start_time":"2026-02-20T11:31:45.905292","status":"completed"},"tags":[]},"source":["## Simple Example\n","\n","### Without Scheduling\n","\n","LR = 0.01 for all 30 epochs\n","\n","Result:\n","- Fast initial progress  \n","- Later oscillation around the minimum  \n","\n","### With Scheduling\n","\n","Epoch 1–10   → 0.01<br>\n","Epoch 11–20  → 0.001<br>\n","Epoch 21–30  → 0.0001\n","\n","Result:\n","- Early: Large steps  \n","- Later: Small, precise steps  \n","- Smoother convergence  "]},{"cell_type":"markdown","id":"e6241043","metadata":{"papermill":{"duration":0.004661,"end_time":"2026-02-20T11:31:45.919259","exception":false,"start_time":"2026-02-20T11:31:45.914598","status":"completed"},"tags":[]},"source":["## Common Types of LR Scheduling\n","\n","- Step Decay  \n","- Exponential Decay  \n","- Cosine Annealing  \n","- Reduce on Plateau  \n","- Warmup + Decay  \n","- Cyclical Learning Rate  \n","\n","> Learning rate scheduling is the technique of dynamically adjusting the learning rate during training to improve convergence speed and stability."]},{"cell_type":"markdown","id":"d4a54636","metadata":{"papermill":{"duration":0.004519,"end_time":"2026-02-20T11:31:45.928368","exception":false,"start_time":"2026-02-20T11:31:45.923849","status":"completed"},"tags":[]},"source":["# StepLR - Discrete Learning Rate Decay\n","\n","StepLR is a learning rate scheduler that reduces the learning rate by a fixed factor (`gamma`) after a fixed number of epochs (`step_size`).\n","\n","It implements **piecewise-constant decay***.\n","\n","Instead of smoothly decreasing the learning rate, it drops it in sudden steps.\n","\n","### StepLR Formula\n","\n","$$\n","\\boxed{\\alpha_t = \\alpha_0 \\cdot \\gamma^{\\left\\lfloor \\frac{t}{\\text{step\\_size}} \\right\\rfloor}}\n","$$\n","\n","Where:\n","\n","- $\\alpha_t$ → learning rate at epoch $t$\n","- $ t $ → Current epoch  \n","- $\\alpha_0$ → initial learning rate\n","- $\\gamma$ → decay factor (e.g., 0.1)\n","- $\\text{step\\_size}$ → number of epochs before decay\n","- $\\lfloor \\cdot \\rfloor$ → floor function (round down)\n","\n","**Intuition**\n","\n","Think of StepLR as:\n","\n","> \"Train normally for some time → then suddenly reduce step size → repeat.\"\n","\n","It allows:\n","\n","- Fast learning early  \n","- More careful learning later  "]},{"cell_type":"markdown","id":"510adcfb","metadata":{"papermill":{"duration":0.004555,"end_time":"2026-02-20T11:31:45.937757","exception":false,"start_time":"2026-02-20T11:31:45.933202","status":"completed"},"tags":[]},"source":["---\n","\n","### <p style=\"color:orange;text-align:center;\">*What is Piecewise-Constant Decay? (Optional)</p>\n","\n","**Piecewise-constant decay** is a function that:\n","\n","- Stays constant for a period of time  \n","- Then suddenly drops to a new constant value  \n","- Repeats this pattern  \n","\n","It does not change smoothly.  \n","It changes in discrete jumps.\n","\n","\n","Imagine a staircase:\n","\n","\n","Level 1  ──────────<br>\n","↓<br>\n","Level 2  ──────────<br>\n","↓<br>\n","Level 3  ──────────\n","\n","\n","Each flat region is constant.  \n","Each drop happens at specific intervals.\n","\n","That staircase shape = piecewise-constant behavior.\n","\n","### Mathematical View (StepLR Example)\n","\n","For StepLR:\n","\n","$$\n","\\alpha_t = \\alpha_0 \\cdot \\gamma^{\\left\\lfloor \\frac{t}{\\text{step\\_size}} \\right\\rfloor}\n","$$\n","\n","The learning rate:\n","\n","- Remains constant within each interval  \n","- Changes only when $ t $ crosses multiples of `step_size`\n","\n","### Simple Example\n","\n","Let:\n","\n","- $ \\alpha_0 = 0.01 $\n","- $ \\gamma = 0.1 $\n","- $ \\text{step\\_size} = 5 $\n","\n","Then:\n","\n","| Epoch | Learning Rate |\n","|-------|---------------|\n","| 0–4   | 0.01          |\n","| 5–9   | 0.001         |\n","| 10–14 | 0.0001        |\n","\n","Notice:\n","\n","- Within each range → LR is constant  \n","- At epoch 5 and 10 → LR drops suddenly  \n","\n","That is **piecewise-constant decay**.\n","\n","\n","### Why It's Called \"Piecewise\"\n","\n","- \"Piecewise\" → defined in separate intervals (pieces)\n","- \"Constant\" → value does not change within each interval\n","- \"Decay\" → value decreases over time\n","\n","> Piecewise-constant decay is a step-like schedule where a value remains constant for fixed intervals and then decreases abruptly at predefined points.\n","\n","---"]},{"cell_type":"markdown","id":"9a2418b6","metadata":{"papermill":{"duration":0.004509,"end_time":"2026-02-20T11:31:45.946943","exception":false,"start_time":"2026-02-20T11:31:45.942434","status":"completed"},"tags":[]},"source":["## What the Floor Function Does\n","\n","$$\n","\\left\\lfloor \\frac{t}{10} \\right\\rfloor\n","$$\n","\n","If `step_size = 10`:\n","\n","| Epoch | t/10 | Floor | Power of γ |\n","|-------|------|-------|------------|\n","| 1–10  | <1   | 0     | γ⁰ = 1 |\n","| 11–20 | 1–2  | 1     | γ¹ |\n","| 21–30 | 2–3  | 2     | γ² |\n","\n","This creates the **staircase pattern**."]},{"cell_type":"markdown","id":"867d47a2","metadata":{"papermill":{"duration":0.004736,"end_time":"2026-02-20T11:31:45.956427","exception":false,"start_time":"2026-02-20T11:31:45.951691","status":"completed"},"tags":[]},"source":["## Manual Example\n","\n","Given:\n","\n","- $\\alpha_0 = 0.01$\n","- $\\gamma = 0.1$\n","- step_size = 10\n","\n","\n","### Epoch 1:\n","\n","$$\n","\\alpha_1 = 0.01 \\cdot 0.1^{\\lfloor 1/10 \\rfloor}\n","$$\n","\n","$$\n","= 0.01 \\cdot 0.1^0\n","$$\n","\n","$$\n","= 0.01 \\cdot 1\n","$$\n","\n","$$\n","= 0.01\n","$$\n","\n","\n","### Epoch 10:\n","\n","$$\n","\\alpha_{10} = 0.01 \\cdot 0.1^{\\lfloor 10/10 \\rfloor}\n","$$\n","\n","$$\n","= 0.01 \\cdot 0.1^1\n","$$\n","\n","$$\n","= 0.001\n","$$\n","\n","So decay happens right after epoch 10.\n","\n","\n","### Epoch 15:\n","\n","$$\n","\\alpha_{15} = 0.01 \\cdot 0.1^{\\lfloor 15/10 \\rfloor}\n","$$\n","\n","$$\n","= 0.01 \\cdot 0.1^1\n","$$\n","\n","$$\n","= 0.001\n","$$\n","\n","Learning rate remains constant until next boundary.\n","\n","\n","### Epoch 25:\n","\n","$$\n","\\alpha_{25} = 0.01 \\cdot 0.1^{\\lfloor 25/10 \\rfloor}\n","$$\n","\n","$$\n","= 0.01 \\cdot 0.1^2\n","$$\n","\n","$$\n","= 0.0001\n","$$\n","\n","\n","### Final Schedule\n","\n","| Epoch | LR |\n","|--------|------|\n","| 1–9 | 0.01 |\n","| 10–19 | 0.001 |\n","| 20–29 | 0.0001 |\n","\n","Notice the **sudden drops**."]},{"cell_type":"markdown","id":"b1d08df6","metadata":{"papermill":{"duration":0.004662,"end_time":"2026-02-20T11:31:45.965678","exception":false,"start_time":"2026-02-20T11:31:45.961016","status":"completed"},"tags":[]},"source":["## How to Choose `gamma`\n","\n","`gamma` controls how aggressively you reduce the learning rate:\n","\n","$$\n","\\alpha_{\\text{new}} = \\alpha_{\\text{old}} \\cdot \\gamma\n","$$\n","\n","So the real question is:\n","\n","> How big should each decay jump be?\n","\n","Let’s approach this strategically.\n","\n","\n","### 1️. First-Principles View\n","\n","Learning rate controls step size:\n","\n","$$\n","\\Delta \\theta = -\\alpha \\nabla L\n","$$\n","\n","Reducing LR changes:\n","\n","- Exploration intensity  \n","- Convergence speed  \n","- Stability  \n","\n","`gamma` determines how sharply you transition from exploration → refinement.\n","\n","\n","### 2️. Standard Practical Values\n","\n","Most commonly used values:\n","\n","| Gamma | Effect |\n","|-------|--------|\n","| 0.1   | Strong decay (10× smaller) |\n","| 0.5   | Moderate decay (2× smaller) |\n","| 0.8–0.9 | Gentle decay |\n","\n","### Rule of thumb:\n","- Computer vision (ImageNet-style): **0.1**\n","- Smaller datasets: **0.5**\n","- Fine-tuning: **0.1 or smaller**\n","\n","\n","### 3. Strategic Way to Choose Gamma\n","\n","Instead of guessing, think in terms of training phases.\n","\n","Ask:\n","\n","1. How far am I from convergence?\n","2. Do I need sharp stabilization or gradual refinement?\n","\n","#### Case A: Large Model, Large Dataset\n","\n","Use:\n","$$\n","\\gamma = 0.1\n","$$\n","\n","Why?\n","\n","- You want clear phase transitions.\n","- Early phase = aggressive learning.\n","- Later phase = precise convergence.\n","\n","Strong drop is fine because gradients are stable.\n","\n","#### Case B: Small Dataset / Noisy Gradients\n","\n","Use:\n","$$\n","\\gamma = 0.5\n","$$\n","\n","Why?\n","\n","- Large abrupt drops may stall learning.\n","- Gentler decay avoids optimizer shock.\n","\n","#### Case C: Fine-Tuning Pretrained Model\n","\n","Often:\n","$$\n","\\gamma = 0.1 \\text{ or } 0.2\n","$$\n","\n","Because:\n","\n","- You are already near a good minimum.\n","- You want fast stabilization.\n","\n","### 4️. Quantitative Thinking (Better Way)\n","\n","Decide how small you want LR at the end.\n","\n","If:\n","\n","- Initial LR = $0.01$\n","- Final desired LR ≈ $0.0001$\n","- You decay 2 times\n","\n","Then solve:\n","\n","$$\n","0.01 \\cdot \\gamma^2 = 0.0001\n","$$\n","\n","$$\n","\\gamma^2 = 0.01\n","$$\n","\n","$$\n","\\gamma = 0.1\n","$$\n","\n","So instead of guessing gamma,\n","**work backward from desired final LR.**\n","\n","This is the cleanest method.\n","\n","### Warning: Too Small Gamma\n","\n","If:\n","\n","$$\n","\\gamma = 0.01\n","$$\n","\n","Then LR collapses too fast.\n","\n","You lose exploration early.\n","Training may stall.\n","\n","\n","### Warning: Too Large Gamma\n","\n","If:\n","\n","$$\n","\\gamma = 0.9\n","$$\n","\n","Decay barely matters.\n","You may oscillate too long.\n","\n","\n","### Practical Recommendation Framework\n","\n","Choose gamma based on:\n","\n","1. Desired final LR\n","2. Number of decay steps\n","3. Dataset size\n","4. Stability of gradients\n","\n","Most robust default:\n","\n","$$\n","\\gamma = 0.1\n","$$\n","\n","Unless you have reason not to."]},{"cell_type":"markdown","id":"dc034dcd","metadata":{"papermill":{"duration":0.004485,"end_time":"2026-02-20T11:31:45.974842","exception":false,"start_time":"2026-02-20T11:31:45.970357","status":"completed"},"tags":[]},"source":["## PyTorch Implementation\n","\n","```python\n","# Create a StepLR scheduler object\n","scheduler = torch.optim.lr_scheduler.StepLR(\n","    optimizer,        # The optimizer whose learning rate we want to control\n","    step_size=10,     # Number of epochs to wait before reducing the learning rate\n","    gamma=0.1         # Multiplicative decay factor (new_lr = old_lr * gamma)\n",")\n","````\n","### What This Actually Means\n","\n","* The learning rate will remain unchanged for 10 epochs.\n","\n","* At epoch 10 → LR becomes:\n","\n","  $$\n","  \\text{LR} = \\text{LR} \\times 0.1\n","  $$\n","\n","* At epoch 20 → it is multiplied by 0.1 again.\n","\n","* This creates the staircase (piecewise-constant) decay pattern.\n","\n","\n","At each epoch:\n","\n","```python\n","# Call this once after each epoch\n","scheduler.step()\n","```\n","\n","### What `scheduler.step()` Does\n","\n","* It updates the learning rate based on the current epoch count.\n","\n","* Internally, it checks:\n","\n","  $$\n","  \\left\\lfloor \\frac{\\text{current\\_epoch}}{\\text{step\\_size}} \\right\\rfloor\n","  $$\n","\n","* If the epoch crosses a decay boundary (10, 20, 30...),\n","  it applies the multiplicative drop.\n","\n","\n","### Important Detail (Often Missed)\n","\n","Typical training loop:\n","\n","```python\n","for epoch in range(num_epochs):\n","    train(...)\n","    validate(...)\n","    scheduler.step()   # Step AFTER each epoch\n","```\n","\n","If you call `scheduler.step()` in the wrong place (e.g., before training),\n","your decay timing shifts by one epoch.\n","\n","**Notes:**\n","\n","* `step_size` controls when decay happens.\n","* `gamma` controls how much decay happens.\n","* `scheduler.step()` triggers the update.\n"]},{"cell_type":"markdown","id":"a8532d3c","metadata":{"papermill":{"duration":0.004531,"end_time":"2026-02-20T11:31:45.983942","exception":false,"start_time":"2026-02-20T11:31:45.979411","status":"completed"},"tags":[]},"source":["## Why It Works\n","\n","Recall optimization phases:\n","\n","1️. Early → large LR helps exploration<br>\n","2️. Later → smaller LR helps convergence\n","\n","StepLR forces a manual phase transition."]},{"cell_type":"markdown","id":"007fbf27","metadata":{"papermill":{"duration":0.004631,"end_time":"2026-02-20T11:31:45.993305","exception":false,"start_time":"2026-02-20T11:31:45.988674","status":"completed"},"tags":[]},"source":["## Weakness of StepLR\n","\n","Abrupt decay can:\n","\n","* Shock optimizer momentum buffers\n","* Cause temporary instability\n","* Reduce LR too early\n","* Waste exploration capacity\n","\n","Momentum-based optimizers especially feel this shock because:\n","\n","$$\n","\\text{velocity}_{t+1} = \\beta v_t + \\alpha \\nabla L\n","$$\n","\n","Sudden drop in $\\alpha$ changes effective velocity."]},{"cell_type":"markdown","id":"7b1affd3","metadata":{"papermill":{"duration":0.004543,"end_time":"2026-02-20T11:31:46.002382","exception":false,"start_time":"2026-02-20T11:31:45.997839","status":"completed"},"tags":[]},"source":["---\n","\n","### <p style=\"text-align:center; color:orange; font-size:18px;\"> Why Abrupt LR Drops Can Be a Problem (Optional)<p>\n","\n","Let’s break this from first principles.\n","\n","1️⃣ **What Momentum Is Really Doing**\n","\n","For momentum SGD:\n","\n","$$\n","v_{t+1} = \\beta v_t + \\nabla L_t\n","$$\n","\n","$$\n","\\theta_{t+1} = \\theta_t - \\alpha v_{t+1}\n","$$\n","\n","Key idea:\n","\n","- $v_t$ = **accumulated direction**\n","- $\\alpha$ = **step size multiplier**\n","\n","Momentum builds up velocity over time.  \n","It smooths gradients and accelerates movement in consistent directions.\n","\n","Think of it as a rolling ball gaining speed downhill.\n","\n","\n","2️⃣ **What Happens Before Decay**\n","\n","Suppose:\n","\n","- Learning rate: $\\alpha = 0.01$\n","- Momentum velocity is large (because training has been progressing steadily)\n","\n","Updates look like:\n","\n","$$\n","\\Delta \\theta \\approx -0.01 \\cdot v_t\n","$$\n","\n","The system is tuned to this step size.\n","\n","\n","3️⃣ **Sudden StepLR Drop**\n","\n","At epoch 10:\n","\n","$$\n","\\alpha \\rightarrow 0.001\n","$$\n","\n","But notice something:\n","\n","- $v_t$ is still large (built using old scale)\n","- Only $\\alpha$ changed\n","\n","Now updates become:\n","\n","$$\n","\\Delta \\theta \\approx -0.001 \\cdot v_t\n","$$\n","\n","That is a 10× smaller step instantly.\n","\n","\n","4️⃣ **Why This Feels Like a “Shock”**\n","\n","The optimizer dynamics were stable at:\n","\n","$$\n","\\text{velocity size }  ×  \\text{ learning rate}  =  \\text{effective step}\n","$$\n","\n","\n","Suddenly:\n","\n","- Velocity is large\n","- Learning rate shrinks sharply\n","\n","So:\n","\n","- Effective step collapses\n","- Momentum needs time to re-adjust\n","- Training temporarily slows or becomes inconsistent\n","\n","It’s like:\n","\n","> Driving at 100 km/h and instantly switching to first gear.\n","\n","System needs time to re-balance.\n","\n","5️⃣ **Why Smooth Decay Is More Stable**\n","\n","With smooth decay (e.g., exponential or cosine):\n","\n","$$\n","\\alpha_t = \\alpha_0 e^{-kt}\n","$$\n","\n","Learning rate shrinks gradually.\n","\n","Momentum adapts gradually too.\n","\n","No sudden system shock.\n","\n","\n","6️⃣ **\"Reduce LR Too Early\" Problem**\n","\n","StepLR forces decay at fixed epochs.\n","\n","But what if:\n","\n","- Model is still far from minimum?\n","- Gradients are still large?\n","- Loss is decreasing fast?\n","\n","Then reducing LR early:\n","\n","- Slows exploration\n","- Makes convergence slower than necessary\n","- Traps you in suboptimal regions\n","\n","This is why adaptive schedulers (e.g., ReduceLROnPlateau) often work better.\n","\n","\n","**Simple Mental Model**\n","\n","Without momentum:\n","- StepLR = less problematic\n","\n","With momentum:\n","- You are scaling a moving object suddenly\n","- System needs time to stabilize\n","\n","> StepLR causes sudden learning rate drops that disrupt the balance between accumulated momentum and step size, leading to temporary instability or slowed progress.\n","\n","---"]},{"cell_type":"markdown","id":"f1fd2d8a","metadata":{"papermill":{"duration":0.004574,"end_time":"2026-02-20T11:31:46.011678","exception":false,"start_time":"2026-02-20T11:31:46.007104","status":"completed"},"tags":[]},"source":["### <p style=\"text-align:center; color:orange; font-size:18px;\"> “Shock Optimizer Momentum Buffers” What It Actually Means (Optional)</p>\n","\n","\n","1️⃣ **What Is a Momentum Buffer?**\n","\n","In momentum-based optimizers (SGD with momentum, Adam, etc.),  \n","the optimizer keeps an internal variable:\n","\n","$$\n","v_t\n","$$\n","\n","This is often called the **momentum buffer**.\n","\n","It stores a moving average of past gradients:\n","\n","$$\n","v_{t+1} = \\beta v_t + \\nabla L_t\n","$$\n","\n","Think of it as:\n","\n","> Accumulated direction + speed from past steps.\n","\n","It has memory.\n","\n","\n","2️⃣ **Where Learning Rate Enters**\n","\n","The actual parameter update is:\n","\n","$$\n","\\theta_{t+1} = \\theta_t - \\alpha v_{t+1}\n","$$\n","\n","Important:\n","\n","- $v_t$ is built gradually.\n","- $\\alpha$ scales how much of that velocity we apply.\n","\n","3️⃣ **What Happens in StepLR**\n","\n","Before decay:\n","\n","$$\n","\\alpha = 0.01\n","$$\n","\n","Suddenly at epoch 10:\n","\n","$$\n","\\alpha = 0.001\n","$$\n","\n","But the momentum buffer:\n","\n","$$\n","v_t\n","$$\n","\n","is still large because it was built assuming the old learning rate dynamics.\n","\n","\n","4️⃣ **The “Shock”**\n","\n","Suddenly:\n","\n","$$\n","\\Delta \\theta = -0.001 \\cdot v_t\n","$$\n","\n","instead of:\n","\n","$$\n","\\Delta \\theta = -0.01 \\cdot v_t\n","$$\n","\n","So:\n","\n","- The optimizer was moving fast.\n","- Instantly, its effective step becomes 10× smaller.\n","- The stored velocity no longer matches the new step scale.\n","\n","That sudden imbalance = **shock to the momentum buffer**.\n","\n","\n","5️⃣ **What You Observe During Training**\n","\n","Right after a StepLR drop, you may see:\n","\n","- Temporary plateau\n","- Slight loss spike\n","- Slower progress for a few epochs\n","- Momentum re-adjustment period\n","\n","Then training stabilizes again.\n","\n","6️⃣ **Why Smooth Schedules Avoid This**\n","\n","With exponential or cosine decay:\n","\n","- $\\alpha$ changes gradually.\n","- Momentum buffer adapts gradually.\n","- No internal mismatch.\n","\n","No shock.\n","\n","---\n"]},{"cell_type":"markdown","id":"4a927dab","metadata":{"papermill":{"duration":0.00473,"end_time":"2026-02-20T11:31:46.02099","exception":false,"start_time":"2026-02-20T11:31:46.01626","status":"completed"},"tags":[]},"source":["## When StepLR Is Still Effective\n","\n","### 1️. Large Datasets (e.g., ImageNet-Scale Training)\n","\n","On very large datasets:\n","\n","- Gradients are stable (low variance)\n","- Optimization landscape is smoother\n","- Training runs for many epochs\n","\n","Because of this stability:\n","\n","- Abrupt LR drops don’t destabilize training much\n","- The model has enough signal to recover quickly\n","- Predefined decay points often align with learning phases\n","\n","In large-scale vision training, simple schedules are often sufficient.\n","\n","### 2️. Fixed-Length Training Pipelines\n","\n","If you know:\n","\n","- Total epochs = 90\n","- You always train exactly 90\n","- Same dataset, same model, same regime\n","\n","Then you can pre-plan:\n","\n","- Decay at 30\n","- Decay at 60\n","\n","This removes the need for adaptive logic.\n","\n","StepLR works well when:\n","\n","> The optimization trajectory is predictable.\n","\n","\n","### 3️. Classic CNN Training (ResNet-Style)\n","\n","Many landmark CNN papers (e.g., early ResNet training pipelines) used milestone-based decay.\n","\n","Typical pattern:\n","\n","Epoch 0–30   → LR = 0.1<br>\n","Epoch 30–60  → LR = 0.01<br>\n","Epoch 60–90  → LR = 0.001\n","\n","Why it works here:\n","\n","- CNNs on large vision datasets train in phases.\n","- Early phase = rapid representation learning.\n","- Mid phase = feature stabilization.\n","- Late phase = refinement.\n","\n","StepLR aligns naturally with these phases.\n","\n","\n","### 4️. When Milestones Are Known in Advance\n","\n","If historical runs show:\n","\n","- Loss plateaus around epoch 25\n","- Another plateau around epoch 55\n","\n","You can intentionally schedule drops there.\n","\n","This turns StepLR from \"blind schedule\" into \"structured optimization design.\"\n","\n","\n","### 5️. Strategic Insight\n","\n","StepLR is strongest when:\n","\n","- Training dynamics are consistent\n","- Dataset is large\n","- Hyperparameters are well-tuned\n","- You care about reproducibility\n","- Simplicity matters\n","\n","It is weakest when:\n","\n","- Data is small\n","- Training is unstable\n","- Optimal decay timing is unknown\n","- You need adaptive behavior\n","\n","\n","\n","> StepLR works best when the optimization landscape and training duration are predictable enough that fixed milestone-based decay aligns with the natural learning phases.\n","\n"]},{"cell_type":"markdown","id":"2467b18f","metadata":{"papermill":{"duration":0.004671,"end_time":"2026-02-20T11:31:46.030542","exception":false,"start_time":"2026-02-20T11:31:46.025871","status":"completed"},"tags":[]},"source":["# ReduceLROnPlateau - Reactive Learning Rate Control\n","\n","To be continue..."]},{"cell_type":"markdown","id":"fc73108a","metadata":{"papermill":{"duration":0.00456,"end_time":"2026-02-20T11:31:46.039745","exception":false,"start_time":"2026-02-20T11:31:46.035185","status":"completed"},"tags":[]},"source":["---\n","<p style=\"text-align:center; color:skyblue; font-size:18px;\">\n","© 2026 Mostafizur Rahman\n","</p>\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31286,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"papermill":{"default_parameters":{},"duration":3.838994,"end_time":"2026-02-20T11:31:46.364607","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2026-02-20T11:31:42.525613","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}